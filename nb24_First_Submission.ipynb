{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec0'></a>\n",
    "# Outputting a file for 1st submission\n",
    "1. <a href='#sec1'>Import Modules and Data</a><br>\n",
    "<br>\n",
    "2. <a href='#sec2'>Digitize both train and test sets</a><br>\n",
    "<br>\n",
    "3. <a href='#sec3'>Create subset of feature spaces</a>\n",
    "    - Use features from F001 univariate selection<br>\n",
    "<br>\n",
    "4. <a href='#sec4'>Resample train set</a>\n",
    "    - Tomek Link majority\n",
    "    - Undersample majority, oversample minority<br>\n",
    "<br>  \n",
    "5. <a href='#sec5'>Train XGBoost, make a prediction, save result</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>\n",
    "# Import Modules and Data\n",
    "(<a href='#sec0'>back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_processing import (create_contingency_table,\n",
    "                                calculate_conditional_prob_bin,\n",
    "                                encode_my_categorical_labels,\n",
    "                                calculate_conditional_prob_cat,\n",
    "                                estimate_cond_prob_density,\n",
    "                                bin_myFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', header=0)\n",
    "test = pd.read_csv('test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape:  (595212, 59)\n",
      " Test Set Shape:  (892816, 58)\n"
     ]
    }
   ],
   "source": [
    "print('Train Set Shape: ', train.shape)\n",
    "print(' Test Set Shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "# Digtizing train and test sets\n",
    "(<a href='#sec0'>back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total of features:       57\n",
      "# of binary features:      17\n",
      "# of categorical features: 14\n",
      "# of other features:       26\n"
     ]
    }
   ],
   "source": [
    "# Get different kinds of features\n",
    "all_fs = train.columns[2:]\n",
    "binary_fs = sorted([f for f in all_fs if '_bin' in f])\n",
    "categorical_fs = sorted([f for f in all_fs if '_cat' in f])\n",
    "other_fs = sorted([f for f in all_fs\n",
    "            if f not in binary_fs\n",
    "            if f not in categorical_fs])\n",
    "\n",
    "print(\"# total of features: %8d\" % len(all_fs))\n",
    "print(\"# of binary features: %7d\" % len(binary_fs))\n",
    "print(\"# of categorical features: %1d\" % len(categorical_fs))\n",
    "print(\"# of other features: %8d\" % len(other_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Binaries Shape:  (595212, 17)\n",
      " Test Set Binaries Shape:  (892816, 17)\n"
     ]
    }
   ],
   "source": [
    "# Keep Binary Features as they are\n",
    "train_binaries = train[binary_fs]\n",
    "test_binaries = test[binary_fs]\n",
    "\n",
    "print('Train Set Binaries Shape: ', train_binaries.shape)\n",
    "print(' Test Set Binaries Shape: ', test_binaries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Categoricals Shape:  (595212, 184)\n",
      " Test Set Categoricals Shape:  (892816, 184)\n"
     ]
    }
   ],
   "source": [
    "# Encode Categorical Features\n",
    "train_categoricals = []\n",
    "test_categoricals = []\n",
    "\n",
    "for i, fs in enumerate(categorical_fs):\n",
    "    train_categoricals.append(encode_my_categorical_labels(train[fs]))\n",
    "    test_categoricals.append(encode_my_categorical_labels(test[fs]))\n",
    "\n",
    "train_categoricals = pd.concat(train_categoricals, axis=1)\n",
    "test_categoricals = pd.concat(test_categoricals, axis=1)\n",
    "\n",
    "print('Train Set Categoricals Shape: ', train_categoricals.shape)\n",
    "print(' Test Set Categoricals Shape: ', test_categoricals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryohayama/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Ordinal/Continuous Shape:  (595212, 26)\n",
      " Test Set Ordinal/Continuous Shape:  (892816, 26)\n"
     ]
    }
   ],
   "source": [
    "# Digitize Ordinal/Continuous Features\n",
    "train_others = train[other_fs]\n",
    "train_others.loc[:, 'ps_car_12'] = bin_myFeature(train_others.loc[:, 'ps_car_12'], 0, 1.5, bins=20)[1]\n",
    "train_others.loc[:, 'ps_car_13'] = bin_myFeature(train_others.loc[:, 'ps_car_13'], 0, 4, bins=50)[1]\n",
    "train_others.loc[:, 'ps_car_13'] = bin_myFeature(train_others.loc[:, 'ps_car_13'], 0, 4, bins=50)[1]\n",
    "train_others.loc[:, 'ps_car_14'] = bin_myFeature(train_others.loc[:, 'ps_car_14'], 0, 4, bins=40)[1]\n",
    "train_others.loc[:, 'ps_reg_03'] = bin_myFeature(train_others.loc[:, 'ps_reg_03'], 0, 5, bins=50)[1]\n",
    "\n",
    "test_others = test[other_fs]\n",
    "test_others.loc[:, 'ps_car_12'] = bin_myFeature(test_others.loc[:, 'ps_car_12'], 0, 1.5, bins=20)[1]\n",
    "test_others.loc[:, 'ps_car_13'] = bin_myFeature(test_others.loc[:, 'ps_car_13'], 0, 4, bins=50)[1]\n",
    "test_others.loc[:, 'ps_car_13'] = bin_myFeature(test_others.loc[:, 'ps_car_13'], 0, 4, bins=50)[1]\n",
    "test_others.loc[:, 'ps_car_14'] = bin_myFeature(test_others.loc[:, 'ps_car_14'], 0, 4, bins=40)[1]\n",
    "test_others.loc[:, 'ps_reg_03'] = bin_myFeature(test_others.loc[:, 'ps_reg_03'], 0, 5, bins=50)[1]\n",
    "\n",
    "print('Train Set Ordinal/Continuous Shape: ', train_others.shape)\n",
    "print(' Test Set Ordinal/Continuous Shape: ', test_others.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digitized Train Set Shape:  (595212, 228)\n",
      "Digitized  Test Set Shape:  (892816, 227)\n"
     ]
    }
   ],
   "source": [
    "# Re-combined different types of features\n",
    "trainset_digitized = pd.concat([train_others, train_binaries, train_categoricals, train.target], axis=1)\n",
    "testset_digitized = pd.concat([test_others, test_binaries, test_categoricals], axis=1)\n",
    "\n",
    "print('Digitized Train Set Shape: ', trainset_digitized.shape)\n",
    "print('Digitized  Test Set Shape: ', testset_digitized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets\n",
    "if True:\n",
    "    trainset_digitized.to_csv('./data/digitized_trainset1.csv', index=False)\n",
    "    testset_digitized.to_csv('./data/digitized_testset1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>\n",
    "# Selecting Features\n",
    "(<a href='#sec0'>back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of features selected after univariate selection and RFE\n",
    "rfe = pd.read_csv('./data/rfe_features.csv')\n",
    "rfe_features = list(rfe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_ready = trainset_digitized[rfe_features]\n",
    "testset_ready = testset_digitized[rfe_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Set Shape:  (595212, 108)\n",
      "Final  Test Set Shape:  (892816, 108)\n"
     ]
    }
   ],
   "source": [
    "print('Final Train Set Shape: ', trainset_ready.shape)\n",
    "print('Final  Test Set Shape: ', testset_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec4'></a>\n",
    "# Resample Train Set\n",
    "(<a href='#sec0'>back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (595212, 108)\n",
      "y shape:  (595212,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(trainset_ready)\n",
    "y = np.array(trainset_digitized.iloc[:, -1])\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before tomek links: size of X:  (595212, 108)\n",
      "After  tomek links: size of X:  (587812, 108)\n",
      "Before tomek links: class0/class1 = 573518 / 21694\n",
      "After  tomek links: class0/class1 = 566118 / 21694\n",
      "CPU times: user 1h 44min 15s, sys: 611 ms, total: 1h 44min 16s\n",
      "Wall time: 13min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tomek Links to denoise majority\n",
    "if True:\n",
    "    tl = TomekLinks(n_jobs=8, ratio='majority')\n",
    "    X_tl, y_tl = tl.fit_sample(X, y)\n",
    "\n",
    "    print('Before tomek links: size of X: ', X.shape)\n",
    "    print('After  tomek links: size of X: ', X_tl.shape)\n",
    "    print('Before tomek links: class0/class1 = %d / %d' % (len(y)-np.sum(y), np.sum(y)))\n",
    "    print('After  tomek links: class0/class1 = %d / %d' % (len(y_tl)-np.sum(y_tl), np.sum(y_tl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set targets for the number of each class\n",
    "# Here, set class0:class1 = 1:1\n",
    "num_class1 = np.sum(y_tl)\n",
    "num_class1_to_resample = 5 * num_class1\n",
    "num_class0_to_resample = int(3 * num_class1_to_resample)\n",
    "\n",
    "# First, randomly undersample the majority\n",
    "rus = RandomUnderSampler(ratio={0: num_class0_to_resample , 1: num_class1})\n",
    "X_tlrus, y_tlrus = rus.fit_sample(X_tl, y_tl)\n",
    "\n",
    "# Then use SMOTE to oversample the minority\n",
    "smote = SMOTE(ratio={0: num_class0_to_resample , 1: num_class1_to_resample}, n_jobs=4)\n",
    "X_res, y_res = smote.fit_sample(X_tlrus, y_tlrus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling: size of X:  (587812, 108)\n",
      "After  Resampling: size of X:  (433880, 108)\n",
      "Before Resampling: class0/class1 = 566118/ 21694\n",
      "After  Resampling: class0/class1 = 325410/108470\n"
     ]
    }
   ],
   "source": [
    "# Print Resampling Results\n",
    "print('Before Resampling: size of X: ', X_tl.shape)\n",
    "print('After  Resampling: size of X: ', X_res.shape)\n",
    "print('Before Resampling: class0/class1 =%7d/%6d' % (len(y_tl)-np.sum(y_tl), np.sum(y_tl)))\n",
    "print('After  Resampling: class0/class1 =%7d/%6d' % (len(y_res)-np.sum(y_res), np.sum(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec5'></a>\n",
    "# Train XGBoost, predict probabilities, save to a file\n",
    "(<a href='#sec0'>back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=9, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=11, min_child_weight=4, missing=None, n_estimators=200,\n",
       "       n_jobs=8, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train XGBoost\n",
    "clf = XGBClassifier(gamma=9, subsample=0.85, max_depth=11, \n",
    "                    min_child_weight=4, learning_rate=0.05, \n",
    "                    n_estimators=200, n_jobs=8)\n",
    "\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(testset_ready)\n",
    "y_ids = np.array(test.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((892816, 108), (892816,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result = pd.DataFrame({'id': y_ids, 'target': y_probas[:, 1]})\n",
    "prediction_result = prediction_result[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.045769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.028076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.070076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.086788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.026964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.105791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.077828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.052074\n",
       "1   1  0.039917\n",
       "2   2  0.045769\n",
       "3   3  0.028076\n",
       "4   4  0.070076\n",
       "5   5  0.086788\n",
       "6   6  0.026964\n",
       "7   8  0.105791\n",
       "8  10  0.077828\n",
       "9  11  0.084100"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result.to_csv('./porto_seguro_submission_RH4.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
