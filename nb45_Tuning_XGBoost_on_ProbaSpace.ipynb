{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import feature_processing as fp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gini(y_true, y_probas):\n",
    "    auc = roc_auc_score(y_true, y_probas[:, 1])\n",
    "    gini = 2*auc - 1\n",
    "    return gini\n",
    "\n",
    "gini_scorer = make_scorer(my_gini, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape:  (595212, 31)\n",
      "Features: \n",
      " Index(['ps_calc_01_proba', 'ps_calc_02_proba', 'ps_calc_03_proba',\n",
      "       'ps_calc_04_proba', 'ps_calc_05_proba', 'ps_calc_06_proba',\n",
      "       'ps_calc_07_proba', 'ps_calc_08_proba', 'ps_calc_09_proba',\n",
      "       'ps_calc_10_proba', 'ps_calc_11_proba', 'ps_calc_12_proba',\n",
      "       'ps_calc_13_proba', 'ps_calc_14_proba', 'ps_car_11_proba',\n",
      "       'ps_car_12_proba', 'ps_car_13_proba', 'ps_car_14_proba',\n",
      "       'ps_car_15_proba', 'ps_ind_01_proba', 'ps_ind_03_proba',\n",
      "       'ps_ind_14_proba', 'ps_ind_15_proba', 'ps_reg_01_proba',\n",
      "       'ps_reg_02_proba', 'ps_reg_03_proba', 'ind_bin_proba', 'calc_bin_proba',\n",
      "       'car_cat_proba1', 'car_cat_proba2', 'ind_cat_proba'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_ori = pd.read_csv('train.csv', header=0)\n",
    "train = pd.read_csv('./data/train_probas.csv', header=0)\n",
    "target = train_ori.target\n",
    "print('Train Set Shape: ', train.shape)\n",
    "print('Features: \\n', train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036447517859182946"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(train_ori.target)\n",
    "num_target = np.sum(train_ori.target)\n",
    "freq_target = num_target/num_samples\n",
    "freq_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_fs = list(train.columns)\n",
    "used_fs.remove('calc_bin_proba')\n",
    "used_fs.remove('ps_calc_01_proba')\n",
    "used_fs.remove('ps_calc_02_proba')\n",
    "used_fs.remove('ps_calc_03_proba')\n",
    "used_fs.remove('ps_calc_04_proba')\n",
    "used_fs.remove('ps_calc_06_proba')\n",
    "used_fs.remove('ps_calc_08_proba')\n",
    "used_fs.remove('ps_calc_09_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_calc_05_proba', 'ps_calc_07_proba', 'ps_calc_10_proba', 'ps_calc_11_proba', 'ps_calc_12_proba', 'ps_calc_13_proba', 'ps_calc_14_proba', 'ps_car_11_proba', 'ps_car_12_proba', 'ps_car_13_proba', 'ps_car_14_proba', 'ps_car_15_proba', 'ps_ind_01_proba', 'ps_ind_03_proba', 'ps_ind_14_proba', 'ps_ind_15_proba', 'ps_reg_01_proba', 'ps_reg_02_proba', 'ps_reg_03_proba', 'ind_bin_proba', 'car_cat_proba1', 'car_cat_proba2', 'ind_cat_proba']\n"
     ]
    }
   ],
   "source": [
    "print(used_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train[used_fs])\n",
    "y = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595212, 23), (595212,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate = 55\n",
    "\n",
    "# Set targets for the number of each class\n",
    "num_class1 = np.sum(y)\n",
    "num_class1_to_resample = 2 * num_class1\n",
    "num_class0_to_resample = int(1 * num_class1_to_resample)\n",
    "\n",
    "# First, randomly undersample the majority\n",
    "rus = RandomUnderSampler(ratio={0: num_class0_to_resample , 1: num_class1})\n",
    "X_tlrus, y_tlrus = rus.fit_sample(X, y)\n",
    "\n",
    "# Then use SMOTE to oversample the minority\n",
    "smote = SMOTE(ratio={0: num_class0_to_resample , 1: num_class1_to_resample}, n_jobs=4)\n",
    "X_res, y_res = smote.fit_sample(X_tlrus, y_tlrus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 20s, sys: 143 ms, total: 10min 20s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[0, 0.5, 1, 2, 4, 8, 16]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.449769</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.653379</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>16</td>\n",
       "      <td>{'gamma': 16}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313039</td>\n",
       "      <td>0.787940</td>\n",
       "      <td>0.301058</td>\n",
       "      <td>0.790185</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.570851</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.568160</td>\n",
       "      <td>0.143552</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.346357</td>\n",
       "      <td>0.109786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.452895</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>0.652474</td>\n",
       "      <td>0.714112</td>\n",
       "      <td>8</td>\n",
       "      <td>{'gamma': 8}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.312531</td>\n",
       "      <td>0.815232</td>\n",
       "      <td>0.297645</td>\n",
       "      <td>0.815442</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.614149</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.611627</td>\n",
       "      <td>0.140462</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.347425</td>\n",
       "      <td>0.101229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.512664</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.647898</td>\n",
       "      <td>0.790850</td>\n",
       "      <td>4</td>\n",
       "      <td>{'gamma': 4}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300641</td>\n",
       "      <td>0.871670</td>\n",
       "      <td>0.291148</td>\n",
       "      <td>0.875085</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.706053</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.710592</td>\n",
       "      <td>0.189395</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.082552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.471373</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.647821</td>\n",
       "      <td>0.824032</td>\n",
       "      <td>2</td>\n",
       "      <td>{'gamma': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.304157</td>\n",
       "      <td>0.898818</td>\n",
       "      <td>0.287307</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.745874</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.749795</td>\n",
       "      <td>0.133742</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.352139</td>\n",
       "      <td>0.076217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.583085</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.647036</td>\n",
       "      <td>0.828695</td>\n",
       "      <td>0</td>\n",
       "      <td>{'gamma': 0}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.299906</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>0.288523</td>\n",
       "      <td>0.908019</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.741793</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.758776</td>\n",
       "      <td>0.272114</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.352845</td>\n",
       "      <td>0.078642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.474842</td>\n",
       "      <td>0.049909</td>\n",
       "      <td>0.646623</td>\n",
       "      <td>0.832511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.299208</td>\n",
       "      <td>0.911348</td>\n",
       "      <td>0.287475</td>\n",
       "      <td>0.909269</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.756039</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.753389</td>\n",
       "      <td>0.137142</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.353306</td>\n",
       "      <td>0.077806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.465114</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>0.645294</td>\n",
       "      <td>0.827073</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gamma': 1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.296931</td>\n",
       "      <td>0.909865</td>\n",
       "      <td>0.284458</td>\n",
       "      <td>0.900939</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.751936</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.130281</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.354627</td>\n",
       "      <td>0.078426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "6       2.449769         0.029700         0.653379          0.679284   \n",
       "5       2.452895         0.039162         0.652474          0.714112   \n",
       "4       2.512664         0.047619         0.647898          0.790850   \n",
       "3       2.471373         0.048881         0.647821          0.824032   \n",
       "0       2.583085         0.049270         0.647036          0.828695   \n",
       "1       2.474842         0.049909         0.646623          0.832511   \n",
       "2       2.465114         0.049071         0.645294          0.827073   \n",
       "\n",
       "  param_gamma          params  rank_test_score  split0_test_score  \\\n",
       "6          16   {'gamma': 16}                1           0.313039   \n",
       "5           8    {'gamma': 8}                2           0.312531   \n",
       "4           4    {'gamma': 4}                3           0.300641   \n",
       "3           2    {'gamma': 2}                4           0.304157   \n",
       "0           0    {'gamma': 0}                5           0.299906   \n",
       "1         0.5  {'gamma': 0.5}                6           0.299208   \n",
       "2           1    {'gamma': 1}                7           0.296931   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "6            0.787940           0.301058            0.790185   \n",
       "5            0.815232           0.297645            0.815442   \n",
       "4            0.871670           0.291148            0.875085   \n",
       "3            0.898818           0.287307            0.901641   \n",
       "0            0.906190           0.288523            0.908019   \n",
       "1            0.911348           0.287475            0.909269   \n",
       "2            0.909865           0.284458            0.900939   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "6           0.999696            0.570851           0.999724   \n",
       "5           0.999885            0.614149           0.999833   \n",
       "4           0.999924            0.706053           0.999879   \n",
       "3           0.999911            0.745874           0.999909   \n",
       "0           0.999791            0.741793           0.999926   \n",
       "1           0.999895            0.756039           0.999914   \n",
       "2           0.999866            0.751936           0.999922   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "6            0.568160      0.143552        0.001167        0.346357   \n",
       "5            0.611627      0.140462        0.001138        0.347425   \n",
       "4            0.710592      0.189395        0.001106        0.352019   \n",
       "3            0.749795      0.133742        0.001147        0.352139   \n",
       "0            0.758776      0.272114        0.000908        0.352845   \n",
       "1            0.753389      0.137142        0.001001        0.353306   \n",
       "2            0.745550      0.130281        0.000607        0.354627   \n",
       "\n",
       "   std_train_score  \n",
       "6         0.109786  \n",
       "5         0.101229  \n",
       "4         0.082552  \n",
       "3         0.076217  \n",
       "0         0.078642  \n",
       "1         0.077806  \n",
       "2         0.078426  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 16}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "[CV] gamma=14 ........................................................\n",
      "[CV] ......................................... gamma=14, total=   3.2s\n",
      "[CV] gamma=14 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................................... gamma=14, total=   2.6s\n",
      "[CV] gamma=14 ........................................................\n",
      "[CV] ......................................... gamma=14, total=   2.4s\n",
      "[CV] gamma=14 ........................................................\n",
      "[CV] ......................................... gamma=14, total=   2.4s\n",
      "[CV] gamma=15 ........................................................\n",
      "[CV] ......................................... gamma=15, total=   2.7s\n",
      "[CV] gamma=15 ........................................................\n",
      "[CV] ......................................... gamma=15, total=   2.7s\n",
      "[CV] gamma=15 ........................................................\n",
      "[CV] ......................................... gamma=15, total=   2.4s\n",
      "[CV] gamma=15 ........................................................\n",
      "[CV] ......................................... gamma=15, total=   2.4s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ......................................... gamma=16, total=   2.6s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ......................................... gamma=16, total=   2.7s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ......................................... gamma=16, total=   2.4s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ......................................... gamma=16, total=   2.4s\n",
      "[CV] gamma=17 ........................................................\n",
      "[CV] ......................................... gamma=17, total=   2.7s\n",
      "[CV] gamma=17 ........................................................\n",
      "[CV] ......................................... gamma=17, total=   2.7s\n",
      "[CV] gamma=17 ........................................................\n",
      "[CV] ......................................... gamma=17, total=   2.4s\n",
      "[CV] gamma=17 ........................................................\n",
      "[CV] ......................................... gamma=17, total=   2.6s\n",
      "[CV] gamma=18 ........................................................\n",
      "[CV] ......................................... gamma=18, total=   2.7s\n",
      "[CV] gamma=18 ........................................................\n",
      "[CV] ......................................... gamma=18, total=   2.7s\n",
      "[CV] gamma=18 ........................................................\n",
      "[CV] ......................................... gamma=18, total=   2.5s\n",
      "[CV] gamma=18 ........................................................\n",
      "[CV] ......................................... gamma=18, total=   2.4s\n",
      "[CV] gamma=19 ........................................................\n",
      "[CV] ......................................... gamma=19, total=   2.8s\n",
      "[CV] gamma=19 ........................................................\n",
      "[CV] ......................................... gamma=19, total=   2.7s\n",
      "[CV] gamma=19 ........................................................\n",
      "[CV] ......................................... gamma=19, total=   2.4s\n",
      "[CV] gamma=19 ........................................................\n",
      "[CV] ......................................... gamma=19, total=   2.4s\n",
      "[CV] gamma=20 ........................................................\n",
      "[CV] ......................................... gamma=20, total=   5.4s\n",
      "[CV] gamma=20 ........................................................\n",
      "[CV] ......................................... gamma=20, total=   4.5s\n",
      "[CV] gamma=20 ........................................................\n",
      "[CV] ......................................... gamma=20, total=   2.4s\n",
      "[CV] gamma=20 ........................................................\n",
      "[CV] ......................................... gamma=20, total=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 59s, sys: 335 ms, total: 10min 59s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[14, 15, 16, 17, 18, 19, 20]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=2, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.629913</td>\n",
       "      <td>0.031713</td>\n",
       "      <td>0.655342</td>\n",
       "      <td>0.682566</td>\n",
       "      <td>14</td>\n",
       "      <td>{'gamma': 14}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317010</td>\n",
       "      <td>0.789783</td>\n",
       "      <td>0.304780</td>\n",
       "      <td>0.791627</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.574381</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.574476</td>\n",
       "      <td>0.351451</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.344475</td>\n",
       "      <td>0.108140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.503843</td>\n",
       "      <td>0.030724</td>\n",
       "      <td>0.654943</td>\n",
       "      <td>0.680920</td>\n",
       "      <td>15</td>\n",
       "      <td>{'gamma': 15}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315266</td>\n",
       "      <td>0.788290</td>\n",
       "      <td>0.304990</td>\n",
       "      <td>0.790470</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.572620</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>0.572301</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.344834</td>\n",
       "      <td>0.108463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.547935</td>\n",
       "      <td>0.030323</td>\n",
       "      <td>0.653818</td>\n",
       "      <td>0.678770</td>\n",
       "      <td>17</td>\n",
       "      <td>{'gamma': 17}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.314085</td>\n",
       "      <td>0.787272</td>\n",
       "      <td>0.301792</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.569258</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.569074</td>\n",
       "      <td>0.117287</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.345907</td>\n",
       "      <td>0.109606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.973806</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.653813</td>\n",
       "      <td>0.677283</td>\n",
       "      <td>20</td>\n",
       "      <td>{'gamma': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313306</td>\n",
       "      <td>0.786294</td>\n",
       "      <td>0.302643</td>\n",
       "      <td>0.788103</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>0.567383</td>\n",
       "      <td>1.092654</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.345859</td>\n",
       "      <td>0.109917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.551605</td>\n",
       "      <td>0.030138</td>\n",
       "      <td>0.653477</td>\n",
       "      <td>0.678428</td>\n",
       "      <td>18</td>\n",
       "      <td>{'gamma': 18}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313671</td>\n",
       "      <td>0.787343</td>\n",
       "      <td>0.300844</td>\n",
       "      <td>0.788654</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>0.569191</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.568525</td>\n",
       "      <td>0.106891</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.346249</td>\n",
       "      <td>0.109572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.485035</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.653379</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>16</td>\n",
       "      <td>{'gamma': 16}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.313039</td>\n",
       "      <td>0.787940</td>\n",
       "      <td>0.301058</td>\n",
       "      <td>0.790185</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.570851</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.568160</td>\n",
       "      <td>0.139256</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.346357</td>\n",
       "      <td>0.109786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.530990</td>\n",
       "      <td>0.028808</td>\n",
       "      <td>0.653156</td>\n",
       "      <td>0.677588</td>\n",
       "      <td>19</td>\n",
       "      <td>{'gamma': 19}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.313090</td>\n",
       "      <td>0.786721</td>\n",
       "      <td>0.300190</td>\n",
       "      <td>0.788174</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>0.567837</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.567620</td>\n",
       "      <td>0.174037</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.346546</td>\n",
       "      <td>0.109861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       2.629913         0.031713         0.655342          0.682566   \n",
       "1       2.503843         0.030724         0.654943          0.680920   \n",
       "3       2.547935         0.030323         0.653818          0.678770   \n",
       "6       3.973806         0.029811         0.653813          0.677283   \n",
       "4       2.551605         0.030138         0.653477          0.678428   \n",
       "2       2.485035         0.029735         0.653379          0.679284   \n",
       "5       2.530990         0.028808         0.653156          0.677588   \n",
       "\n",
       "  param_gamma         params  rank_test_score  split0_test_score  \\\n",
       "0          14  {'gamma': 14}                1           0.317010   \n",
       "1          15  {'gamma': 15}                2           0.315266   \n",
       "3          17  {'gamma': 17}                3           0.314085   \n",
       "6          20  {'gamma': 20}                4           0.313306   \n",
       "4          18  {'gamma': 18}                5           0.313671   \n",
       "2          16  {'gamma': 16}                6           0.313039   \n",
       "5          19  {'gamma': 19}                7           0.313090   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.789783           0.304780            0.791627   \n",
       "1            0.788290           0.304990            0.790470   \n",
       "3            0.787272           0.301792            0.789474   \n",
       "6            0.786294           0.302643            0.788103   \n",
       "4            0.787343           0.300844            0.788654   \n",
       "2            0.787940           0.301058            0.790185   \n",
       "5            0.786721           0.300190            0.788174   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999846            0.574381           0.999734   \n",
       "1           0.999808            0.572620           0.999706   \n",
       "3           0.999775            0.569258           0.999620   \n",
       "6           0.999737            0.567352           0.999567   \n",
       "4           0.999690            0.569191           0.999702   \n",
       "2           0.999696            0.570851           0.999724   \n",
       "5           0.999673            0.567837           0.999671   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.574476      0.351451        0.000511        0.344475   \n",
       "1            0.572301      0.153285        0.000765        0.344834   \n",
       "3            0.569074      0.117287        0.000659        0.345907   \n",
       "6            0.567383      1.092654        0.001633        0.345859   \n",
       "4            0.568525      0.106891        0.001047        0.346249   \n",
       "2            0.568160      0.139256        0.001345        0.346357   \n",
       "5            0.567620      0.174037        0.001054        0.346546   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.108140  \n",
       "1         0.108463  \n",
       "3         0.109606  \n",
       "6         0.109917  \n",
       "4         0.109572  \n",
       "2         0.109786  \n",
       "5         0.109861  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 14}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 13s, sys: 47.7 ms, total: 3min 13s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[12, 13, 14]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.265459</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.653978</td>\n",
       "      <td>0.687695</td>\n",
       "      <td>12</td>\n",
       "      <td>{'gamma': 12}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.848408</td>\n",
       "      <td>0.651269</td>\n",
       "      <td>0.688580</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.526097</td>\n",
       "      <td>0.271981</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.131584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.167287</td>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.653789</td>\n",
       "      <td>0.686061</td>\n",
       "      <td>13</td>\n",
       "      <td>{'gamma': 13}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.848071</td>\n",
       "      <td>0.651232</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.523106</td>\n",
       "      <td>0.150094</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.280964</td>\n",
       "      <td>0.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.189132</td>\n",
       "      <td>0.040832</td>\n",
       "      <td>0.653158</td>\n",
       "      <td>0.684199</td>\n",
       "      <td>14</td>\n",
       "      <td>{'gamma': 14}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.309373</td>\n",
       "      <td>0.846053</td>\n",
       "      <td>0.650921</td>\n",
       "      <td>0.685162</td>\n",
       "      <td>0.999205</td>\n",
       "      <td>0.521381</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.281625</td>\n",
       "      <td>0.132548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       2.265459         0.042089         0.653978          0.687695   \n",
       "1       2.167287         0.041582         0.653789          0.686061   \n",
       "2       2.189132         0.040832         0.653158          0.684199   \n",
       "\n",
       "  param_gamma         params  rank_test_score  split0_test_score  \\\n",
       "0          12  {'gamma': 12}                1           0.311302   \n",
       "1          13  {'gamma': 13}                2           0.310976   \n",
       "2          14  {'gamma': 14}                3           0.309373   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.848408           0.651269            0.688580   \n",
       "1            0.848071           0.651232            0.687008   \n",
       "2            0.846053           0.650921            0.685162   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.999386            0.526097      0.271981        0.001171   \n",
       "1           0.999183            0.523106      0.150094        0.002028   \n",
       "2           0.999205            0.521381      0.168600        0.000228   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.280914         0.131584  \n",
       "1        0.280964         0.132668  \n",
       "2        0.281625         0.132548  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 12}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   37.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 31s, sys: 262 ms, total: 5min 32s\n",
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[11, 11.5, 12, 12.5, 13]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.514440</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.653978</td>\n",
       "      <td>0.687695</td>\n",
       "      <td>12</td>\n",
       "      <td>{'gamma': 12}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.848408</td>\n",
       "      <td>0.651269</td>\n",
       "      <td>0.688580</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.526097</td>\n",
       "      <td>0.446070</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.131584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.667029</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.653962</td>\n",
       "      <td>0.686548</td>\n",
       "      <td>12.5</td>\n",
       "      <td>{'gamma': 12.5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.311346</td>\n",
       "      <td>0.848204</td>\n",
       "      <td>0.651329</td>\n",
       "      <td>0.688370</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.523071</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.280834</td>\n",
       "      <td>0.132741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.336222</td>\n",
       "      <td>0.043903</td>\n",
       "      <td>0.653950</td>\n",
       "      <td>0.692173</td>\n",
       "      <td>11</td>\n",
       "      <td>{'gamma': 11}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.310849</td>\n",
       "      <td>0.851225</td>\n",
       "      <td>0.651635</td>\n",
       "      <td>0.693231</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.532063</td>\n",
       "      <td>0.154089</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.281098</td>\n",
       "      <td>0.130299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.208923</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.653914</td>\n",
       "      <td>0.689545</td>\n",
       "      <td>11.5</td>\n",
       "      <td>{'gamma': 11.5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.311459</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.650972</td>\n",
       "      <td>0.689821</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.528331</td>\n",
       "      <td>0.186620</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.280831</td>\n",
       "      <td>0.131518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.205669</td>\n",
       "      <td>0.041892</td>\n",
       "      <td>0.653789</td>\n",
       "      <td>0.686061</td>\n",
       "      <td>13</td>\n",
       "      <td>{'gamma': 13}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.848071</td>\n",
       "      <td>0.651232</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.523106</td>\n",
       "      <td>0.135290</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.280964</td>\n",
       "      <td>0.132668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2       2.514440         0.041428         0.653978          0.687695   \n",
       "3       2.667029         0.042880         0.653962          0.686548   \n",
       "0       2.336222         0.043903         0.653950          0.692173   \n",
       "1       2.208923         0.042993         0.653914          0.689545   \n",
       "4       2.205669         0.041892         0.653789          0.686061   \n",
       "\n",
       "  param_gamma           params  rank_test_score  split0_test_score  \\\n",
       "2          12    {'gamma': 12}                1           0.311302   \n",
       "3        12.5  {'gamma': 12.5}                2           0.311346   \n",
       "0          11    {'gamma': 11}                3           0.310849   \n",
       "1        11.5  {'gamma': 11.5}                4           0.311459   \n",
       "4          13    {'gamma': 13}                5           0.310976   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "2            0.848408           0.651269            0.688580   \n",
       "3            0.848204           0.651329            0.688370   \n",
       "0            0.851225           0.651635            0.693231   \n",
       "1            0.850482           0.650972            0.689821   \n",
       "4            0.848071           0.651232            0.687008   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "2           0.999386            0.526097      0.446070        0.001032   \n",
       "3           0.999235            0.523071      0.543300        0.002196   \n",
       "0           0.999389            0.532063      0.154089        0.000284   \n",
       "1           0.999336            0.528331      0.186620        0.001937   \n",
       "4           0.999183            0.523106      0.135290        0.001624   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "2        0.280914         0.131584  \n",
       "3        0.280834         0.132741  \n",
       "0        0.281098         0.130299  \n",
       "1        0.280831         0.131518  \n",
       "4        0.280964         0.132668  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 12}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 29s, sys: 130 ms, total: 6min 29s\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'max_depth':[4, 5, 6, 7, 8, 9, 10]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.220155</td>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.654131</td>\n",
       "      <td>0.698337</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310939</td>\n",
       "      <td>0.857767</td>\n",
       "      <td>0.652095</td>\n",
       "      <td>0.697280</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.539965</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.281058</td>\n",
       "      <td>0.129744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.219281</td>\n",
       "      <td>0.041664</td>\n",
       "      <td>0.653978</td>\n",
       "      <td>0.687695</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.848408</td>\n",
       "      <td>0.651269</td>\n",
       "      <td>0.688580</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.526097</td>\n",
       "      <td>0.161329</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.131584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.515114</td>\n",
       "      <td>0.044897</td>\n",
       "      <td>0.653869</td>\n",
       "      <td>0.692023</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.851954</td>\n",
       "      <td>0.651876</td>\n",
       "      <td>0.692805</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>0.531311</td>\n",
       "      <td>0.171466</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.281103</td>\n",
       "      <td>0.130903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921760</td>\n",
       "      <td>0.041282</td>\n",
       "      <td>0.653212</td>\n",
       "      <td>0.683291</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.310244</td>\n",
       "      <td>0.845258</td>\n",
       "      <td>0.650325</td>\n",
       "      <td>0.685639</td>\n",
       "      <td>0.999089</td>\n",
       "      <td>0.518974</td>\n",
       "      <td>0.149112</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.281226</td>\n",
       "      <td>0.133216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.636504</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.652849</td>\n",
       "      <td>0.678246</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.310773</td>\n",
       "      <td>0.842128</td>\n",
       "      <td>0.650007</td>\n",
       "      <td>0.679774</td>\n",
       "      <td>0.997790</td>\n",
       "      <td>0.512837</td>\n",
       "      <td>0.119862</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.280479</td>\n",
       "      <td>0.134437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.421727</td>\n",
       "      <td>0.031471</td>\n",
       "      <td>0.652691</td>\n",
       "      <td>0.673707</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.311246</td>\n",
       "      <td>0.839186</td>\n",
       "      <td>0.649545</td>\n",
       "      <td>0.675233</td>\n",
       "      <td>0.997305</td>\n",
       "      <td>0.506701</td>\n",
       "      <td>0.131934</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.280090</td>\n",
       "      <td>0.135741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.206690</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.651232</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.309671</td>\n",
       "      <td>0.835049</td>\n",
       "      <td>0.649628</td>\n",
       "      <td>0.672271</td>\n",
       "      <td>0.994420</td>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.230564</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.279548</td>\n",
       "      <td>0.136810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "6       3.220155         0.053107         0.654131          0.698337   \n",
       "4       2.219281         0.041664         0.653978          0.687695   \n",
       "5       2.515114         0.044897         0.653869          0.692023   \n",
       "3       1.921760         0.041282         0.653212          0.683291   \n",
       "2       1.636504         0.036401         0.652849          0.678246   \n",
       "1       1.421727         0.031471         0.652691          0.673707   \n",
       "0       1.206690         0.027192         0.651232          0.669100   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "6              10  {'max_depth': 10}                1           0.310939   \n",
       "4               8   {'max_depth': 8}                2           0.311302   \n",
       "5               9   {'max_depth': 9}                3           0.310600   \n",
       "3               7   {'max_depth': 7}                4           0.310244   \n",
       "2               6   {'max_depth': 6}                5           0.310773   \n",
       "1               5   {'max_depth': 5}                6           0.311246   \n",
       "0               4   {'max_depth': 4}                7           0.309671   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "6            0.857767           0.652095            0.697280   \n",
       "4            0.848408           0.651269            0.688580   \n",
       "5            0.851954           0.651876            0.692805   \n",
       "3            0.845258           0.650325            0.685639   \n",
       "2            0.842128           0.650007            0.679774   \n",
       "1            0.839186           0.649545            0.675233   \n",
       "0            0.835049           0.649628            0.672271   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "6           0.999382            0.539965      0.577184        0.005438   \n",
       "4           0.999386            0.526097      0.161329        0.000853   \n",
       "5           0.999155            0.531311      0.171466        0.000325   \n",
       "3           0.999089            0.518974      0.149112        0.002785   \n",
       "2           0.997790            0.512837      0.119862        0.004852   \n",
       "1           0.997305            0.506701      0.131934        0.002237   \n",
       "0           0.994420            0.499980      0.230564        0.001896   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "6        0.281058         0.129744  \n",
       "4        0.280914         0.131584  \n",
       "5        0.281103         0.130903  \n",
       "3        0.281226         0.133216  \n",
       "2        0.280479         0.134437  \n",
       "1        0.280090         0.135741  \n",
       "0        0.279548         0.136810  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 59s, sys: 355 ms, total: 12min 59s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'max_depth':[10, 12, 14, 16, 18, 20]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.545010</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.654284</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311310</td>\n",
       "      <td>0.860683</td>\n",
       "      <td>0.652222</td>\n",
       "      <td>0.708008</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.195980</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.127048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.909013</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.654131</td>\n",
       "      <td>0.698337</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310939</td>\n",
       "      <td>0.857767</td>\n",
       "      <td>0.652095</td>\n",
       "      <td>0.697280</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.539965</td>\n",
       "      <td>0.332388</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.281058</td>\n",
       "      <td>0.129744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.899714</td>\n",
       "      <td>0.062454</td>\n",
       "      <td>0.653193</td>\n",
       "      <td>0.719110</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.307130</td>\n",
       "      <td>0.871590</td>\n",
       "      <td>0.652996</td>\n",
       "      <td>0.717180</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.568560</td>\n",
       "      <td>1.006761</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.282648</td>\n",
       "      <td>0.123719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.508980</td>\n",
       "      <td>0.081721</td>\n",
       "      <td>0.652783</td>\n",
       "      <td>0.742162</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305946</td>\n",
       "      <td>0.883332</td>\n",
       "      <td>0.652817</td>\n",
       "      <td>0.739514</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.603640</td>\n",
       "      <td>0.265277</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.283185</td>\n",
       "      <td>0.114199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.909323</td>\n",
       "      <td>0.068806</td>\n",
       "      <td>0.652606</td>\n",
       "      <td>0.726492</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 16}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.307241</td>\n",
       "      <td>0.875190</td>\n",
       "      <td>0.650998</td>\n",
       "      <td>0.727948</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.576337</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.282656</td>\n",
       "      <td>0.122011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.322566</td>\n",
       "      <td>0.092848</td>\n",
       "      <td>0.652253</td>\n",
       "      <td>0.733587</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 18}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.305256</td>\n",
       "      <td>0.877384</td>\n",
       "      <td>0.651988</td>\n",
       "      <td>0.734976</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.588401</td>\n",
       "      <td>1.208798</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>0.283439</td>\n",
       "      <td>0.117981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1       3.545010         0.052264         0.654284          0.706064   \n",
       "0       2.909013         0.049367         0.654131          0.698337   \n",
       "2       4.899714         0.062454         0.653193          0.719110   \n",
       "5       6.508980         0.081721         0.652783          0.742162   \n",
       "3       4.909323         0.068806         0.652606          0.726492   \n",
       "4       7.322566         0.092848         0.652253          0.733587   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "1              12  {'max_depth': 12}                1           0.311310   \n",
       "0              10  {'max_depth': 10}                2           0.310939   \n",
       "2              14  {'max_depth': 14}                3           0.307130   \n",
       "5              20  {'max_depth': 20}                4           0.305946   \n",
       "3              16  {'max_depth': 16}                5           0.307241   \n",
       "4              18  {'max_depth': 18}                6           0.305256   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "1            0.860683           0.652222            0.708008   \n",
       "0            0.857767           0.652095            0.697280   \n",
       "2            0.871590           0.652996            0.717180   \n",
       "5            0.883332           0.652817            0.739514   \n",
       "3            0.875190           0.650998            0.727948   \n",
       "4            0.877384           0.651988            0.734976   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "1           0.999344            0.549500      0.195980        0.001788   \n",
       "0           0.999382            0.539965      0.332388        0.002395   \n",
       "2           0.999477            0.568560      1.006761        0.002431   \n",
       "5           0.999610            0.603640      0.265277        0.000315   \n",
       "3           0.999602            0.576337      0.222700        0.001646   \n",
       "4           0.999540            0.588401      1.208798        0.023632   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "1        0.280891         0.127048  \n",
       "0        0.281058         0.129744  \n",
       "2        0.282648         0.123719  \n",
       "5        0.283185         0.114199  \n",
       "3        0.282656         0.122011  \n",
       "4        0.283439         0.117981  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 55s, sys: 693 ms, total: 11min 56s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, max_depth=12, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'min_child_weight':[1, 2, 3, 4, 5, 6]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.855780</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.654466</td>\n",
       "      <td>0.709297</td>\n",
       "      <td>4</td>\n",
       "      <td>{'min_child_weight': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310930</td>\n",
       "      <td>0.861017</td>\n",
       "      <td>0.653071</td>\n",
       "      <td>0.710895</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.555980</td>\n",
       "      <td>1.624253</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.281076</td>\n",
       "      <td>0.124536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.606918</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.709164</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_child_weight': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.312031</td>\n",
       "      <td>0.862154</td>\n",
       "      <td>0.651729</td>\n",
       "      <td>0.711126</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.554213</td>\n",
       "      <td>0.384636</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>0.125724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.946060</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>0.654284</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>1</td>\n",
       "      <td>{'min_child_weight': 1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.311310</td>\n",
       "      <td>0.860683</td>\n",
       "      <td>0.652222</td>\n",
       "      <td>0.708008</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.211516</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.127048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.313027</td>\n",
       "      <td>0.085936</td>\n",
       "      <td>0.654003</td>\n",
       "      <td>0.710163</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_child_weight': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.310934</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.714265</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.553692</td>\n",
       "      <td>3.421310</td>\n",
       "      <td>0.018089</td>\n",
       "      <td>0.281086</td>\n",
       "      <td>0.126117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.926041</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.653991</td>\n",
       "      <td>0.709518</td>\n",
       "      <td>3</td>\n",
       "      <td>{'min_child_weight': 3}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.309558</td>\n",
       "      <td>0.863871</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.713038</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.551643</td>\n",
       "      <td>0.514151</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.281653</td>\n",
       "      <td>0.127491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.849449</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.653838</td>\n",
       "      <td>0.708746</td>\n",
       "      <td>6</td>\n",
       "      <td>{'min_child_weight': 6}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.309062</td>\n",
       "      <td>0.860412</td>\n",
       "      <td>0.653120</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.889682</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.281810</td>\n",
       "      <td>0.125259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3       4.855780         0.054562         0.654466          0.709297   \n",
       "4       3.606918         0.054348         0.654342          0.709164   \n",
       "0       3.946060         0.070613         0.654284          0.706064   \n",
       "1       7.313027         0.085936         0.654003          0.710163   \n",
       "2       3.926041         0.059109         0.653991          0.709518   \n",
       "5       4.849449         0.068096         0.653838          0.708746   \n",
       "\n",
       "  param_min_child_weight                   params  rank_test_score  \\\n",
       "3                      4  {'min_child_weight': 4}                1   \n",
       "4                      5  {'min_child_weight': 5}                2   \n",
       "0                      1  {'min_child_weight': 1}                3   \n",
       "1                      2  {'min_child_weight': 2}                4   \n",
       "2                      3  {'min_child_weight': 3}                5   \n",
       "5                      6  {'min_child_weight': 6}                6   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "3           0.310930            0.861017           0.653071   \n",
       "4           0.312031            0.862154           0.651729   \n",
       "0           0.311310            0.860683           0.652222   \n",
       "1           0.310934            0.862533           0.651656   \n",
       "2           0.309558            0.863871           0.652970   \n",
       "5           0.309062            0.860412           0.653120   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "3            0.710895           0.999422            0.555980      1.624253   \n",
       "4            0.711126           0.999288            0.554213      0.384636   \n",
       "0            0.708008           0.999344            0.549500      0.211516   \n",
       "1            0.714265           0.999444            0.553692      3.421310   \n",
       "2            0.713038           0.999467            0.551643      0.514151   \n",
       "5            0.712177           0.999355            0.553648      0.889682   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "3        0.001652        0.281076         0.124536  \n",
       "4        0.001980        0.280576         0.125724  \n",
       "0        0.025640        0.280891         0.127048  \n",
       "1        0.018089        0.281086         0.126117  \n",
       "2        0.001338        0.281653         0.127491  \n",
       "5        0.022698        0.281810         0.125259  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 4}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 24s, sys: 257 ms, total: 9min 24s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, max_depth=12, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'colsample_bytree':[0.2, 0.4, 0.6, 0.8]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.762114</td>\n",
       "      <td>0.042247</td>\n",
       "      <td>0.655093</td>\n",
       "      <td>0.703952</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316899</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.807907</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.598547</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.601798</td>\n",
       "      <td>0.486023</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.344775</td>\n",
       "      <td>0.103786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.198576</td>\n",
       "      <td>0.042535</td>\n",
       "      <td>0.654920</td>\n",
       "      <td>0.713591</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.6}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.317804</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.302329</td>\n",
       "      <td>0.814011</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.610120</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.222292</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.344897</td>\n",
       "      <td>0.100501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.737922</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>0.653202</td>\n",
       "      <td>0.684596</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'colsample_bytree': 0.2}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.312350</td>\n",
       "      <td>0.792977</td>\n",
       "      <td>0.300525</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.575966</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.574842</td>\n",
       "      <td>0.318258</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.346790</td>\n",
       "      <td>0.109194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.285190</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.653142</td>\n",
       "      <td>0.721961</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.8}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312499</td>\n",
       "      <td>0.819089</td>\n",
       "      <td>0.300609</td>\n",
       "      <td>0.824583</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.622069</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>0.622104</td>\n",
       "      <td>0.324075</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.346613</td>\n",
       "      <td>0.099894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1       3.762114         0.042247         0.655093          0.703952   \n",
       "2       4.198576         0.042535         0.654920          0.713591   \n",
       "0       2.737922         0.036874         0.653202          0.684596   \n",
       "3       5.285190         0.040032         0.653142          0.721961   \n",
       "\n",
       "  param_colsample_bytree                     params  rank_test_score  \\\n",
       "1                    0.4  {'colsample_bytree': 0.4}                1   \n",
       "2                    0.6  {'colsample_bytree': 0.6}                2   \n",
       "0                    0.2  {'colsample_bytree': 0.2}                3   \n",
       "3                    0.8  {'colsample_bytree': 0.8}                4   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "1           0.316899            0.807556           0.303801   \n",
       "2           0.317804            0.814130           0.302329   \n",
       "0           0.312350            0.792977           0.300525   \n",
       "3           0.312499            0.819089           0.300609   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "1            0.807907           0.999906            0.598547   \n",
       "2            0.814011           0.999819            0.610120   \n",
       "0            0.794598           0.999988            0.575966   \n",
       "3            0.824583           0.999846            0.622069   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "1           0.999767            0.601798      0.486023        0.001071   \n",
       "2           0.999726            0.616103      0.222292        0.002028   \n",
       "0           0.999946            0.574842      0.318258        0.002410   \n",
       "3           0.999613            0.622104      0.324075        0.002347   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "1        0.344775         0.103786  \n",
       "2        0.344897         0.100501  \n",
       "0        0.346790         0.109194  \n",
       "3        0.346613         0.099894  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 57s, sys: 162 ms, total: 9min 57s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, max_depth=12, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'colsample_bytree':[0.3, 0.35, 0.4, 0.45, 0.5]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.897900</td>\n",
       "      <td>0.040699</td>\n",
       "      <td>0.655492</td>\n",
       "      <td>0.700162</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'colsample_bytree': 0.35}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318234</td>\n",
       "      <td>0.806133</td>\n",
       "      <td>0.303981</td>\n",
       "      <td>0.804824</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.593584</td>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.344422</td>\n",
       "      <td>0.105321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.540318</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>0.655093</td>\n",
       "      <td>0.703952</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.4}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.316899</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.807907</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.598547</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.601798</td>\n",
       "      <td>0.197415</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.344775</td>\n",
       "      <td>0.103786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.792248</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>0.654827</td>\n",
       "      <td>0.693820</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'colsample_bytree': 0.3}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316766</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>0.302720</td>\n",
       "      <td>0.801468</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.586292</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.587017</td>\n",
       "      <td>0.261831</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.345119</td>\n",
       "      <td>0.107165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.767294</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.654404</td>\n",
       "      <td>0.706616</td>\n",
       "      <td>0.45</td>\n",
       "      <td>{'colsample_bytree': 0.45}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.810028</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.810144</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.604409</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.601885</td>\n",
       "      <td>0.208110</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.345499</td>\n",
       "      <td>0.103474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.030485</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.654125</td>\n",
       "      <td>0.709128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bytree': 0.5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.810967</td>\n",
       "      <td>0.302820</td>\n",
       "      <td>0.812295</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.605931</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.607319</td>\n",
       "      <td>0.185479</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.345715</td>\n",
       "      <td>0.102505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1       2.897900         0.040699         0.655492          0.700162   \n",
       "2       3.540318         0.042450         0.655093          0.703952   \n",
       "0       2.792248         0.039376         0.654827          0.693820   \n",
       "3       3.767294         0.043510         0.654404          0.706616   \n",
       "4       4.030485         0.041475         0.654125          0.709128   \n",
       "\n",
       "  param_colsample_bytree                      params  rank_test_score  \\\n",
       "1                   0.35  {'colsample_bytree': 0.35}                1   \n",
       "2                    0.4   {'colsample_bytree': 0.4}                2   \n",
       "0                    0.3   {'colsample_bytree': 0.3}                3   \n",
       "3                   0.45  {'colsample_bytree': 0.45}                4   \n",
       "4                    0.5   {'colsample_bytree': 0.5}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "1           0.318234            0.806133           0.303981   \n",
       "2           0.316899            0.807556           0.303801   \n",
       "0           0.316766            0.800500           0.302720   \n",
       "3           0.314066            0.810028           0.303782   \n",
       "4           0.314046            0.810967           0.302820   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "1            0.804824           0.999876            0.596109   \n",
       "2            0.807907           0.999906            0.598547   \n",
       "0            0.801468           0.999936            0.586292   \n",
       "3            0.810144           0.999931            0.604409   \n",
       "4            0.812295           0.999888            0.605931   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "1           0.999878            0.593584      0.162156        0.000508   \n",
       "2           0.999767            0.601798      0.197415        0.000987   \n",
       "0           0.999885            0.587017      0.261831        0.000865   \n",
       "3           0.999839            0.601885      0.208110        0.000490   \n",
       "4           0.999746            0.607319      0.185479        0.001768   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "1        0.344422         0.105321  \n",
       "2        0.344775         0.103786  \n",
       "0        0.345119         0.107165  \n",
       "3        0.345499         0.103474  \n",
       "4        0.345715         0.102505  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.35}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 95.5 ms, total: 3min 34s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=12, max_depth=12, colsample_bytree=0.35, \n",
    "                    min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'subsample':[0.7, 0.75, 0.8, 0.85, 0.9]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=2, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.173739</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.269248</td>\n",
       "      <td>0.687533</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'subsample': 0.85}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.357276</td>\n",
       "      <td>0.375066</td>\n",
       "      <td>0.030547</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.088028</td>\n",
       "      <td>0.312467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.307759</td>\n",
       "      <td>0.052627</td>\n",
       "      <td>0.267999</td>\n",
       "      <td>0.686582</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.9}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354261</td>\n",
       "      <td>0.373164</td>\n",
       "      <td>0.355962</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.086262</td>\n",
       "      <td>0.313418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.124574</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.266976</td>\n",
       "      <td>0.683768</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'subsample': 0.75}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.345093</td>\n",
       "      <td>0.367536</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.078116</td>\n",
       "      <td>0.316232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.295239</td>\n",
       "      <td>0.048873</td>\n",
       "      <td>0.264959</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'subsample': 0.7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351832</td>\n",
       "      <td>0.373515</td>\n",
       "      <td>0.180890</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.086873</td>\n",
       "      <td>0.313242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.083397</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>0.263670</td>\n",
       "      <td>0.685777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.8}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.177699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349641</td>\n",
       "      <td>0.371554</td>\n",
       "      <td>0.247022</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.085971</td>\n",
       "      <td>0.314223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3       2.173739         0.050052         0.269248          0.687533   \n",
       "4       2.307759         0.052627         0.267999          0.686582   \n",
       "1       2.124574         0.045752         0.266976          0.683768   \n",
       "0       2.295239         0.048873         0.264959          0.686758   \n",
       "2       2.083397         0.047958         0.263670          0.685777   \n",
       "\n",
       "  param_subsample               params  rank_test_score  split0_test_score  \\\n",
       "3            0.85  {'subsample': 0.85}                1           0.181221   \n",
       "4             0.9   {'subsample': 0.9}                2           0.181737   \n",
       "1            0.75  {'subsample': 0.75}                3           0.188860   \n",
       "0             0.7   {'subsample': 0.7}                4           0.178086   \n",
       "2             0.8   {'subsample': 0.8}                5           0.177699   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  std_fit_time  \\\n",
       "3                 1.0           0.357276            0.375066      0.030547   \n",
       "4                 1.0           0.354261            0.373164      0.355962   \n",
       "1                 1.0           0.345093            0.367536      0.010914   \n",
       "0                 1.0           0.351832            0.373515      0.180890   \n",
       "2                 1.0           0.349641            0.371554      0.247022   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "3        0.005178        0.088028         0.312467  \n",
       "4        0.007151        0.086262         0.313418  \n",
       "1        0.002634        0.078116         0.316232  \n",
       "0        0.000971        0.086873         0.313242  \n",
       "2        0.001459        0.085971         0.314223  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.85}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 49s, sys: 537 ms, total: 14min 49s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(subsample=0.85, max_depth=12, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[10, 11, 12, 13, 14]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.124289</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.652934</td>\n",
       "      <td>0.708438</td>\n",
       "      <td>14</td>\n",
       "      <td>{'gamma': 14}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308474</td>\n",
       "      <td>0.862481</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.711082</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.551751</td>\n",
       "      <td>0.315135</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.282142</td>\n",
       "      <td>0.126869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.577828</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>0.650630</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>13</td>\n",
       "      <td>{'gamma': 13}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.301764</td>\n",
       "      <td>0.870250</td>\n",
       "      <td>0.650509</td>\n",
       "      <td>0.720839</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.567367</td>\n",
       "      <td>0.357956</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.284905</td>\n",
       "      <td>0.123655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.505554</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.650225</td>\n",
       "      <td>0.733382</td>\n",
       "      <td>12</td>\n",
       "      <td>{'gamma': 12}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.301625</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.649478</td>\n",
       "      <td>0.740031</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.582883</td>\n",
       "      <td>0.596210</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.284944</td>\n",
       "      <td>0.120259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.892877</td>\n",
       "      <td>0.066951</td>\n",
       "      <td>0.648628</td>\n",
       "      <td>0.753985</td>\n",
       "      <td>11</td>\n",
       "      <td>{'gamma': 11}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.887876</td>\n",
       "      <td>0.648104</td>\n",
       "      <td>0.760052</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.614029</td>\n",
       "      <td>1.336605</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.286397</td>\n",
       "      <td>0.111880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.880703</td>\n",
       "      <td>0.085808</td>\n",
       "      <td>0.647508</td>\n",
       "      <td>0.780029</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gamma': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.293196</td>\n",
       "      <td>0.902363</td>\n",
       "      <td>0.649638</td>\n",
       "      <td>0.778772</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.658951</td>\n",
       "      <td>0.475573</td>\n",
       "      <td>0.026318</td>\n",
       "      <td>0.288437</td>\n",
       "      <td>0.099377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "4       6.124289         0.051282         0.652934          0.708438   \n",
       "3       6.577828         0.054108         0.650630          0.719486   \n",
       "2       6.505554         0.060474         0.650225          0.733382   \n",
       "1       7.892877         0.066951         0.648628          0.753985   \n",
       "0       6.880703         0.085808         0.647508          0.780029   \n",
       "\n",
       "  param_gamma         params  rank_test_score  split0_test_score  \\\n",
       "4          14  {'gamma': 14}                1           0.308474   \n",
       "3          13  {'gamma': 13}                2           0.301764   \n",
       "2          12  {'gamma': 12}                3           0.301625   \n",
       "1          11  {'gamma': 11}                4           0.298137   \n",
       "0          10  {'gamma': 10}                5           0.293196   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "4            0.862481           0.650779            0.711082   \n",
       "3            0.870250           0.650509            0.720839   \n",
       "2            0.877232           0.649478            0.740031   \n",
       "1            0.887876           0.648104            0.760052   \n",
       "0            0.902363           0.649638            0.778772   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "4           0.999573            0.551751      0.315135        0.000856   \n",
       "3           0.999641            0.567367      0.357956        0.000938   \n",
       "2           0.999596            0.582883      0.596210        0.003376   \n",
       "1           0.999668            0.614029      1.336605        0.005158   \n",
       "0           0.999715            0.658951      0.475573        0.026318   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "4        0.282142         0.126869  \n",
       "3        0.284905         0.123655  \n",
       "2        0.284944         0.120259  \n",
       "1        0.286397         0.111880  \n",
       "0        0.288437         0.099377  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 14}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 47s, sys: 365 ms, total: 9min 48s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=14, subsample=0.85, max_depth=12, \n",
    "                    min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'learning_rate':[0.1, 0.05, 0.01]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=3, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.216948</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.652934</td>\n",
       "      <td>0.708438</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.308474</td>\n",
       "      <td>0.862481</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.711082</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.551751</td>\n",
       "      <td>0.546897</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.282142</td>\n",
       "      <td>0.126869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.797922</td>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.654132</td>\n",
       "      <td>0.702273</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>0.855361</td>\n",
       "      <td>0.652793</td>\n",
       "      <td>0.705186</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.546272</td>\n",
       "      <td>1.186236</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.281130</td>\n",
       "      <td>0.126202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.452974</td>\n",
       "      <td>0.089329</td>\n",
       "      <td>0.637523</td>\n",
       "      <td>0.687665</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>0.847623</td>\n",
       "      <td>0.650726</td>\n",
       "      <td>0.693357</td>\n",
       "      <td>0.961094</td>\n",
       "      <td>0.522016</td>\n",
       "      <td>0.130637</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.269736</td>\n",
       "      <td>0.132989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       8.216948         0.050987         0.652934          0.708438   \n",
       "1       6.797922         0.070615         0.654132          0.702273   \n",
       "2       6.452974         0.089329         0.637523          0.687665   \n",
       "\n",
       "  param_learning_rate                   params  rank_test_score  \\\n",
       "0                 0.1   {'learning_rate': 0.1}                2   \n",
       "1                0.05  {'learning_rate': 0.05}                1   \n",
       "2                0.01  {'learning_rate': 0.01}                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.308474            0.862481           0.650779   \n",
       "1           0.310501            0.855361           0.652793   \n",
       "2           0.300771            0.847623           0.650726   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.711082           0.999573            0.551751      0.546897   \n",
       "1            0.705186           0.999126            0.546272      1.186236   \n",
       "2            0.693357           0.961094            0.522016      0.130637   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000782        0.282142         0.126869  \n",
       "1        0.001236        0.281130         0.126202  \n",
       "2        0.001473        0.269736         0.132989  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the best classifier so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=14, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=12, min_child_weight=4, missing=None, n_estimators=200,\n",
       "       n_jobs=8, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini=0.314+/-0.011, Best=0.327\n",
      "CPU times: user 4min 5s, sys: 327 ms, total: 4min 5s\n",
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEYCAYAAABRMYxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd4FOXax/HvnU5IoQRCDU26FOlY\nsaCIihVBwAIiKEdRsaC+9nIsyLEcQUBEitJEUVBUFBVR6SBIB5FepYf07P3+MROMHEgCZDOb5P5c\n117Z3Znd/W2ZyT3PPPOMqCrGGGOMMUVJkNcBjDHGGGPymxU4xhhjjClyrMAxxhhjTJFjBY4xxhhj\nihwrcIwxxhhT5FiBY4wxxpgixwocg4hsEpHL3OtPiMhIrzMZY/KHLd8FQ0SGichTeZhvpYi0K4BI\nBUJERovIi+71diKyzetMWazACXAi0lVE5ovIURHZ417vJyLij9dT1X+rau8zfR4RqS4iKiIh2e67\nQ0QyRSTRvWwUkXvO9LVyyZHrAucuoGlupv0i8q2I1Dtunioi8pGI7HO/iwUicvVx84iI9BeRFe48\n20TkYxFp5I/3Zgo/W77POEe+LN/5QVXvVtUX8jBfQ1X9Mb9f3/0sfO77PCIia0WkZ36/TmFiBU4A\nE5GHgLeAQUAFIB64GzgPCDvJY4ILLODpmauqUaoaBdwIvCYi53gdCnjNzVQZ2A68nzVBRMoAPwNp\nQEMgDngDGC8iN2V7jreA+4H+QBmgDvAZcFVBvAFTuNjyXaCylu8qwB5g9Ilmyl6wFVI73PcZAzwI\nvCcidT3O5BkrcAKUiMQCzwP9VHWKqh5Rx1JV7a6qqe58o0XkXRGZISJHgYtF5CoRWSoih0Vkq4g8\ne9xz3yoim93WiP87btqzIvJhttttRORXETkoIsuyN62KyI8i8oKI/OJuMcwUkTh38k/u34PuFkXb\n49+jqi4FVgP1sz1nJ7cJ96D7/Nmn1XfvO+jO0ynbtI4issrNsV1EHhaRksBXQKVsW5WVcvrcVTUZ\nmAw0zXb3g0AicKeq7lLVZFWdALwEDHZbbmoD/wJuUdXvVTVVVZNU9SNVfSWn1zTFjy3fni3fScB4\n4Oxsn8cUEflQRA4Dd4hIkIg8JiJ/uJ/hZHcjJyvL+dk+s60icke27yprV02ciHzhzrNfROaISJA7\nLfsuw3AReVNEdriXN0Uk3J3WTpxW4IfEad3bKXlskXF/SzOA/UDjbNnridOCtV+cFp6bs00rISKD\n3d/OIRH5WURKuNM+FpFd7v0/iUjDvOTwnKraJQAvQAcgAwjJZb7RwCGcrb4gIAJoBzRybzcGdgPX\nufM3wPlnfSEQDvzHfZ3L3OnPAh+61ysD+4CO7nO1d2+Xc6f/CPyB01JRwr39ijutOqDZ8wN3AD9n\nu90SOAjUcW/XAY66rxMKPApswNmaDXWvP+HevgQ4AtR1H7sTuMC9Xhpo5l5vB2zLw2f4onu9JDAO\nWJZt+jzguRM8rob7HuvibHlv9vp3Y5fCcbHl27PlOwqnwJmT7fNIB65zP4MSOK2w83Bae8KB4cAE\nd/5qbq5b3MxlgaYneJ2XgWHuPKHABYC40zZl+z6ed1+rPFAO+BV4Idt7y3DnCXW/pySg9Ene57HP\nwn0vnQAfcI57X0lgK9ATCAHOAf4CGrjTh7jfcWUgGDgXCHen9QKi3c/jTeC3k3y+uX4fBXmxFpzA\nFQf8paoZWXdk22pIFpELs837uar+oqo+VU1R1R9V9Xf39nJgAnCRO+9NwBeq+pM6W4lP4SwEJ9ID\nmKGqM9zn+hZYhLOgZflAVdfpiVs+TqSN+x6OAAtwion17rQuwJeq+q2qpgOv46xwzgXa4KycXlHV\nNFX9HvgCZ0UDzkqqgYjEqOoBVV2SS47jPSwiB3FWXucDt2abFoezgj3ezmzTy55kHmNOxJZvb5bv\nDe7r3JFt2lxV/cz9DJJxNlb+T1W3uZ/hs8BN4uy+6gZ8p6oTVDVdVfep6m8neL10oCJQzZ1vjroV\nwHG6A8+r6h5V3Qs8xz/XPenu9HR1WmQScTaoTqaS+z6TganAAHVa0gCuBjap6geqmuHe/wnQ2W1d\n6gXcr6rbVTVTVX913z+qOkqdVsasz6OJ2woZ0KzACVz7gDjJtk9YVc9V1VLutOzf3dbsDxSR1iLy\ng4jsFZFDOAtsVtNypezzq+pR9/lOpBrOj/9g1gXnn3/FbPPsynY9CWflkZN5qlpKVaNx+h00BP6d\nLdvmbNl8btbKWbnd+7JsdqeBs7+/I7BZRGafqMk8F6+7n211nJVD9pXIX/zzPWepmG36vpPMY8yJ\n2PLtwfKtqhVUtZOq/pFt2tbj5q0GTM32mawGMnH6SFXFadXKzSCcYmqmOJ2tHzvJfP/4TNzr2Xez\n7cteBON+ByKSkG23XGK26Tvc31AM8DZOS1j299X6uO+7O873FIfTOvg/701EgkXkFXeX3WGcFij4\n+zcXsKzACVxzgVTg2jzMe/yWwXhgGlBVVWNxmkqzjsrYibOQAiAikTitDyeyFRjnrhiyLiU1b31K\ncj1NvaruxtmCuMa9awfOQpiVTdys291pVbP2Y7sS3Gmo6kJVvRanqfcznK3NPOU4LtMWnCbqt7L2\nPwPfATcc99oAN+N8RuuAWUAVEWlxKq9nii1bvj1Yvk8W9bjbW4Erj/tcIlR1uzutVq5P6LR2PKSq\nNXF2FQ0QkUtPMOs/PhOc97wjD8+/Rd3O3Op0Kj5+eiowEGgkItdle1+zj3tfUap6D85GWspJ3ls3\nnN/pZUAszkYg/P2bC1hW4AQoVT2I01w5VERuEpFot/NbU5x9qTmJBvaraoqItML5gWaZAlztdpQL\nw9m/e7LfwYfANSJyhVvFR7gd36rk4S3sxWkar3myGUSkLHA9sNK9azJwlYhcKiKhwEM4/wR+Bebj\nbL08KiKh4nSGvAaYKCJhItJdRGLdpu/D/N0svxsoeyrNqW5T/Q6gj3vXGzgL9vsiUsH9HG4B/g94\nRB3rgaHABPczCnPn65rD1psppmz59m75zoNhwEsiUs19H+VEJKsQ/Qi4TERuFpEQESnrfmfHv/er\nReQst4g7hNMCdKJdhROAJ93XiAOexvlezpiqpgGD3ecEZ5dfHXE6oYe6l5YiUt9tORsF/EdEKrm/\nh7bidHiOxvme9gGR/N0iF/CswAlgqvoaMACnM95u9zIcpzL/NYeH9gOeF2c/+NP8vbWDqq7EOdpn\nPM7W3gHghONIqOpWnMr9CZwV2lbgEfLwu1HnaIWXgF/c5tA27qS22ZpVV7vPe5/7mLU4/QL+i7NF\ncQ1wjbtPPs29faU7bShwm6qucZ/3VmCT24R6N07TK+70CcBGN0eOR1lkMwhnZRuuqvtwmu4jgFU4\nC/oA4FZVnZTtMf2Bd3A66x3Eae69Hpiex9c0xYgt354u3zl5C6eFbKb7Gc8DWruvtwVnV9lDOEco\n/QY0OcFz1MZp+U3Eaa0bqqo/nGC+F3H6PS0HfgeWuPfll1FAgohco6pHgMuBrjgbcLuAV3E6DgM8\n7GZYiPPeXsX5LYzF2XW2HWf9Ny8f8/lVVq9uY4wxxpgiw1pwjDHGGFPkWIFjjDHGmCLHChxjjDHG\nFDlW4BhjjDGmyCl0JxaLi4vT6tWrex3DGHMCixcv/ktVy3mdIz/YusaYwJTX9UyhK3CqV6/OokWL\nvI5hjDkBEdmc+1yFg61rjAlMeV3P2C4qY4wxxhQ5VuAYY4wxpsixAscYY4wxRY4VOMYYY4wpcqzA\nMcYYY0yR47cCR0RGicgeEVlxkukiIm+LyAYRWS4izfyVxRhTdNm6xhhzIv5swRkNdMhh+pU4Z1yt\nDfQB3vVjFmNM0TUaW9cYY47jt3FwVPUnEamewyzXAmPVOZ35PBEpJSIVVXWnvzIZY3KWefgwf84a\nReL2dexJOkRwho/o+Cq0unOQ19FOyst1ze+fvcHOfZto3eN5YsNjz/TpjDH5yMuB/ioDW7Pd3ube\n9z8rHRHpg7PlRUJCQoGEM6aoU1UOfTqVA4vnsX/eD0TuSDw2LRyo6l7fXO13COACJw/8tq458O4o\nqm7OYFitKgxs90j+pDXG5ItCMZKxqo4ARgC0aNFCPY5jTKF1IOUAu/dtZO/7Q0ifNZ+Ku30ABIXC\npvJwNDaIyHrxlKzVig93hNAkoQo3X9jU49QF51TXNTVq1yBx83qmLd7EVbUPcXZla8UxJlB4WeBs\n5++NRIAq7n3GmHw0Ztko1s+ZRqllm2i4NpXqeyDOnTbrHEg9vwQNE5rT9qJnKRVTGVXl2iG/cOUl\nFbmnXS1Ps+cTv61rIkuVIRE4t1Ycvccs4ruHLiIqvFBsNxpT5Hm5JE4D7hWRiUBr4JD1vzEmH6Sn\nsHvWM4xeN5vQ+Ye5crHSKtvklLKKr1ltqtxzN/c2uOofD915KJn46Ag+uKMlZaPCCza3//h9XVM9\nLpLH+p9PVHgI2w4kUaV0ZH4+vTHmNPitwBGRCUA7IE5EtgHPAKEAqjoMmAF0BDYASUBPf2Uxpsjz\n+WDvGub9+gazv/+Ji+cE0Snl78klWlQi/toOhLdpT1DVE+9yWrH9ED1HL2RYj+Y0r1a6gIKfuUBZ\n15SNCmfP4RSufecXXrmxMe0bxPvjZYwxeeTPo6huyWW6Av/y1+sbUyykJsKPL7Nw5CT2/BVKzZ3Q\nyR394XDzs6jf636iL7kUEcnxaRZv3k+fsYt58bqzC1VxA4G1rikfE8EHPVvSa/QiktIyuLZp5YJ4\nWWPMCdjOYmMKo/kjSJozmOUHDpM8O5YKf4USBWxuEEutyzpTo2tPQsqUyfPTfbNyN4NvbkK7uuX9\nl7mYaFylFB/1bs2QHzZwTeNKBAXlXFwaY/zDChxjCouMNNJ+eIl3l39MqdlKi/VBxGopYoFZTYRO\nQ6fToeypdQqetXo38TERPNGxvn8yF1N1K0Tz9i3nsPtwCj+s2UPXVja8hTEFzQocYwKc+nwkDhvI\nqi8/J+aPYC7PNu3AhY0o2607/7qoU667oY43bdkOnp++ivdvb5G/gc0xmT5lxE8b2XU4hfsvrX3K\n35Ex5vRZgWNMgNp7eCcrhz1D/Kg5AMQQzJEISKtXjSb/eoKo8y847X+Yny7Zxqtfr+HD3q2oVyEm\nP2ObbCqVKsGkvm259f35pGb4GNihnteRjCk2rMAxJsBoZgYjB3em6fg1xLtHQv1eQ5jVtxmDOw4j\nKizqzJ5flTrx0Uzs05YacSXzIbHJSbnocCb2acPKHYcB5/O3lhxj/M8KHGMCRWoiR38axIcjJnPh\n785d+5sLNR4dxM1NruLmM3x6VeW/328gI9PHgMvrnnFck3elIsM476w4pi3bwazVu3m9cxNCg/15\nrmNjjC1hxgSAjJ9Hs6nT2Wy5zyluDsQKZ309ifM+WkWlJlfl/gS5UFVe+WoNXy7fSY+21fIhsTkd\nlzeI51ByOv0+WkJqRqbXcYwp0qzAMcYrPh/sXM6Kp+qw+u5XSN5cAoC9rWrSds5vhFZvnG8vNX35\nTuZt3Mekvm0oHx2Rb89rTk1EaDAjbm1BaLDwzvcbvI5jTJFmu6iM8YCumM6u5+5j7Y4I4vcFA/DB\nZUG0vO8ZbqrTOd/6aGRk+tiyP4mrG1XksvrliQyzRd5rYSFBvN31HNIzlZ2HkikZHkJMRKjXsYwp\ncmxtZ0xBSktiyeCrKTFmJ1CCeGBjjXCqPPIEr16cf4UNQGpGJv0nLCU8JJi3bznHipsAEhIcREgw\njPplO1+t2MnYXq0pUzLM61jGFCm2xjOmgPww+mHkvS+I3+cUMQsahFL6lefpVOe6fH+t5LRM+oxb\nRFR4CIM659+uLpO/+rWrxdHUDLoMn8uHvVsTH2O7D43JL1bgGONHS3Yv4a3Fb5C+YAlPTfQBwtbG\nsVS//yluP+/MOw+fzPaDydQqF8WTV9UnxI7WCVgiwqMd6hEdEcraXUeswDEmH1mBY0w+25m4k3u/\nv5fNu9fSfqnSb66PmGRnWskne3N5j4f89toHjqYxdu5m7rvkLJ7t1NBvr2Py1z3tnFNsjPl1E+ed\nFcdZ5c9srCNjjBU4xuSLTF8m0/6YxvDlw9meuJ07v8nkxSV6bHqJhCjiX32PEuc09VuGPYdT6PH+\nfC6tH4+NI1c4RYYF0+29eYzu2YoGlWyEaWPOhBU4xpyBlftWMmPjDMauGgtAzFFl6LhM4g4408td\n05jSjwwiuLx/T7a4/2ganYfP5eYWVfnXxWf59bWM/3RuUZWS4SHcNmo+H/ZubafRMOYMWIFjzGnY\ndmQbD89+mJX7VgJQOawUl2zeyg2fh5B+IJTo2mFU/nguEhHp9ywZmT5KR4by0nWNOL92nN9fz/hX\nx0YVKR8dTvWyJcnI9FkfKmNOky05xpwin/p48pcnWblvJV0qXcjHh4MZNWYL14wuQfqBUEr36E6V\n6csKpLhZvfMwHd6aw+GUDCtuipAW1csQFhzETcPmMmv1bq/jGFMoWYFjTB6pKnO2zaHTZ51YvHsx\nVx1Jo/+kKYSOTeTQJqeYqfzWW1R48skCybN0ywFufX8+D1xWm9gSNlBcURMUJDzbqSEDP1nOF8t3\neB3HmELHdlEZkweqymNzHmPGnzMA6LX/MJ0mhrL9UBkAItu0IWHke0hIwSxS6Zk+Bn6ynNduaswl\n9eIL5DVNwWtatRTj7mxNn3GLaFWjjJ1mw5hTYAWOMbn489CfdPqsEwDVUtJ568ejpC2NIg0o3e0W\nyvS6k7AqlQssz/JtB2lQMYbp951PeEhwgb2u8Ub9ijF8N+AiwkOCWbLlAM0SSnsdyZhCwXZRGXMS\n6ZnpXDb5kmPFzW0L0hj0hpC21BmjpEzPnlR4+ukCLW6+XL6TXqMXsmV/khU3xUh4SDBHUtIZMOk3\n3vl+Paqa+4OMKeasBceY4/jUx5TVE3hh4SsAlD6iDB2TRvARp6Ao3a0bZe/uS2j58gWaa/Kirbz+\nzVrG3dmamuVsILjiJjoilMl923Lr+wtITM1kYIe6+XruMmOKGitwjMlm8Y553PHtXQBU2K8M+D6d\n6uuDAKe4qbNgPsEx3oxNsv1AMhP6tKGWFTfFVvmYCCb2acOQHzaQnqmEhViBY8zJWIFjjOvp2QOZ\numkGwZnKy5/5qL5OydqLW2nw68R06IAEF/xuoeGz/6BNzbI82L5Ogb+2CTylS4bx5NUN2HkomVE/\n/8nADvVsrBxjTsCWClPs/frnTDqMa8X0DV/SfomPCa9lUn2dEhQdTdX3RlB/zWpir7qqwIsbVeXV\nr9cwZfE2Ksba0TPmn0qVCGPt7kTuHb+U1IxMr+MYE3CswDHFkqoydf1UmoxpRN+fHuJwYhLvv53J\nXd/4AIjrdw91Fy4g6oILPMv4xrfrmLN+L5P6tqW8nWXaHKdEWDDv3dYcRek/YanXcYwJOLaLyhQ7\n245s46GZd7MqcTMAnTcn03m8M1Be6R49iOt3DyFlyniWLyPThwLXnlOZ3hfWJCbCBvEzJxYeEsyQ\nbs1Ys+sIqkpqho+IUDu6zhiwFhxTzHy96Ws6fXoVqxI3035fMtMm6LHiptwDD1Dhyf/ztLhJy/Bx\n34SljPr5T2qVi7LixuQqJDiIsyvH8uO6vdw8fC4HjqZ5HcmYgGAtOKZY2J+yn27Tb2Z7knNenzFz\nDxD1W2VSDh4mqGRJqg57l8iWLT3NmJyWyd0fLiYiNIg7zqvuaRZT+LSrU455G/fRdcQ8xvVuZaMe\nm2LPWnBMkeZTH6/++jwXTbqI7Um7qXc0jU8+DKHEj9FkHjxMuQceoM6ihZ4XNwBTlmyjTMkwhnRr\nZoP4mVMmIjzWoR7XNKnIO99v8DqOMZ6zFhxTZP206Vv+NXsAAEE+ZeTnaUStCSaTFEKrVqX6+I8I\nKVfO45RwMCmNzfuS6NE6ge6tEggKsrFNzOkREe69pDaZPmXLviQyfD4bFNIUW35twRGRDiKyVkQ2\niMhjJ5ieICI/iMhSEVkuIh39mccUH2MWDD5W3DRKSmXKyDCi1jitIuUfG0itr2YERHGz50gKXYbP\nY9aaPYiIFTenydY1/xQcJPy27SC3vDeP1TsPex3HGE/4rQVHRIKBIUB7YBuwUESmqeqqbLM9CUxW\n1XdFpAEwA6jur0ymeBgw8XK+Td2JqPJ1yvkcGvILGRnJlOrShQrPPhMww9tvP5hMj5Hzuf6cytx3\nyVlexym0bF1zYp2aVEKAW9+fz8jbW9K0aimvIxlToPy5i6oVsEFVNwKIyETgWiD7SkeBrHHvY4Ed\nfsxjirhv13/Oy788w17JpMpe5a1Z5Tn052wASnXtQoVnAqe4AUhJz6TX+TW4tU01r6MUdt6ta9xz\nXganB+ZAe9c0qURkWDCJKRleRzGmwPmzwKkMbM12exvQ+rh5ngVmish9QEngshM9kYj0AfoAJCQk\n5HtQU7jN2TaHF+e9wI6jO0Gg41rljk8zyWQnUZdcQvwTTxToGb9zs3bXET6av5nnOjW080rlD8/W\nNUdXbwfgrEkL4OJTTF1ALq0fD8DQHzdQv2IMF9ct2JPEGuMVr4+iugUYrapVgI7AOBH5n0yqOkJV\nW6hqi3IB0G/CBIa0zDQe+OEB+s3qx46jO7lwTypTPynFHZ86W9OVBg2i6tAhAVXcLNt6kO4j59Oi\nepmAak0qBvyyrslMTAEg7GBSPsfNf21qluWRj5cx4/edXkcxpkD4swVnO1A12+0q7n3Z3Ql0AFDV\nuSISAcQBe/yYyxQB245s48pPrwQgOs3HqDGp6F+hpPMXEhFB9UmTiKgbWCen3LIviV6jF/LqjY25\nrEG813GKEs/WNaruPqogr7cVc9csoTRjerWi5wcLiS0RynlnxXkdyRi/8meBsxCoLSI1cFY2XYFu\nx82zBbgUGC0i9YEIYK8fM5lCLsOXwZR1U3jnt3eISlKe/CadmmuCUJwRf6u+9x4lzz8v4FpHjqSk\nU7VMCSb1bctZ5W23VD7zbl3jcwocDayf20k1rBTLJ/ecS/mYcA6npNtI2aZI81uBo6oZInIv8A0Q\nDIxS1ZUi8jywSFWnAQ8B74nIgzjd9e7QY5tExvzTrqO7aD+lPQDlDipD3s0kay9rufv7E3fPPR6m\nO7mvft/Jy1+t4dsBF1px4weermvcp9BC0IKTpWqZSABuH7WAC+uUo187O4LPFE1+HehPVWfgHI6Z\n/b6ns11fBZznzwymaFBVHp79MAB3bEyi46QwACr2u57Y+14KuBabLJ8s3sYrX6/hgzta2ujEfuTV\nukbdFhwC8+eXo7e6nkOPkfNJTMngkSvqBuwyZMzpKjybHaZY6/nVbSzbu4xeOw8fK27K9ryVUv3/\nHbAr5qOpGYydt5kJd7Xm7MqxXscx/lAIW3CyxMdEMKlvWxZu2s+mfYHfSdqYU1X4lkpTrGRkptNj\nXFsW7/2NihkZ3PSLc6bvuH79KD/wCY/TndxXv+8kLCSIz/qdy1nlo72OY/wkqwVHC+matEzJMCb3\nbUv1spF8sXwHmT7rIWCKjkK6WJqiTlUZvGgwzT9szjJfIlEZPoZNq0Li+hQi27ShXP/7vI54QqrK\n69+s5fWZazmUnB6wrUsmnxw7iqrwfs8iQnqmMnHBVvpPWEpahs/rSMbkCytwTMBRVfrN6sfolaPx\noTy0KYNRg3ykrt0GQKV/v+RxwhNTVZ6bvorv1+xhct+2xEWFex3J+NmxFpxCXsiGhQQx8vYWpGX6\n6DNuESkBOjKzMafCChwTULYnbqfdxAv4efvPlM/I4NdVh2k9wZlW5vbbqPvbUkIrVfI2ZA5qlSvJ\nhD5tKGvFTfGQ1YJTyAscgIjQYIZ2b8aFtcsRXIhbpIzJYgWOCRiT1kzk6k87sj/tEG2Tk/n4z7ps\n+9w5pLXyG/8h/vHHCYqI8Djl/0rL8PHQ5GWs3HGYW9tWJ7aEjS1S3BSWcXByExocRK/za3AwKZ27\nxi7iYFKa15GMOW1W4JiAMGzBIF6c/xIZ6uO/O/fy/PqL2T1lLQDlHxtIzJVXepzwxFLSM7n7w8Uc\nSk63MW6Ko2ND6RSRCscVFxVG9bKRdB0xj71HUr2OY8xp8es4OMbkZvvBP3l0xu0sTz9Ao5RU3g0+\nmz1fxHDgr58BOGv2j4TGB+5pDZ749HeiwkMYfHMTQoNte6HYKZr1DSLCEx3r89as9fQcvYBp/zqf\nINttZQoZK3CMJ1SVx2f158vtPwJQPS2d91o+xZ4XPyPjr/1EXXIJVd75LxKg44scSk4nIjSIgVfW\nIy4q3PosFFNZ9c3qg+tOfHryQkxEeOCyOtzcoioi8FdiqnWcN4VKYP73MEWaqvLwVz2PFTfvBicw\n/c5VJH6zjZRVqyjVtQtVhw4J2OJm75FUugyfy/RlO4mPibDipjjLGujP4xj+VKlUCZZtO8TVb//M\n2l1HvI5jTJ7l6T+IiISJiJ2wxOSLX2fcy8y9i2mWksJvVbtyXrfp7Hj8cfaPGUtkixZUeOYZryOe\n1I6DyXQZMZcrGlbgxmaVvY5jvOZWNmEZ3sbwt6ZVS/F4x3p0Hzmf5dsOeh3HmDzJdReViFwF/AcI\nA2qISFPgGVW93t/hTBGjyuYxHbhftxGGMKTTFChZgw0XtSNj715C4uOp/NabAT043pfLd3JLywTu\nurCm11FMAMg8kgzARSuKchuO49qmlSkRGsykhVtpXKWU13GMyVVe+uA8D7QGfgBQ1d+sNcecssS9\nfPvBRQyMDiI9KIh/t36KiIgE/uzcmYy9e4lo0IDqUz4O2N1S63cfYW9iqhU2pli7vGEFLm9YgQ17\nEtl5KJkLapfzOpIxJ5WX/ybpqnp8m2TR31wx+WfPGt78oA0DYoJJF2HIJUO4PKQZ6y+8iPTNWyhz\n+23U+PSTgC1uVmw/RLeR8+1wWWNch5LTeWDib3y9YpfXUYw5qby04KwWkZuBIBGpAfQH5vk3liky\n1nxJt9kP8nuMM2DfxKsnUuGzeWwc1BeA8o8+StlePb1MmKPFmw/Qd9wiXrq+EVc0rOB1HGMCQvNq\npRnTqxU9Ry8kNSOTa5tafzQTePJS4NwLPA34gE+Bb4DAPY2zCRi+3ybw1M9P8Ht0FA2iqjL80g/Y\ne11X9uxytvqqjhxJ1PnneZxydTZVAAAgAElEQVQyZ+Wiwnmr6zmcd1ac11GMCShnV45lfO/WHEpO\n9zqKMSeUlwLnClUdCAzMukNEbsApdow5Id/n9/Hw9hl8Gx1FmbBYRrcdzo4ut5PhFjc1Z3xJeM3A\n7c/yzcpdfLdqN4M6NyGhbKTXcYwJSLXjowEY8sMGQoKEvhfV8jiRMX/LS6eHJ09w3//ldxBThCwZ\ny+ubp/FtSacwmFL6cTZdcjlpmzdT5s5e1F+zOqCLm8+Wbuf/pq7gtrbVvY5iTKFwY7MqTF60lcEz\n16JqXTRNYDhpC46IXAF0ACqLyH+yTYrB2V1lzD8l7oV3WvBOhDKudCxBBPHr1TPZ0q49QdHRVB0+\njMhmzbxOmaMV2w/xyldrGH9Xa+q4W6fGmJxViI1gUt+23Pb+AmqVi+K6c6xPjvFeTruo9gArgBRg\nZbb7jwCP+TOUKYQyM9B3z+X9cB/DSztjZPx45XR239Eb0tOp+sGogC9utu5PomGlGGbcfwFlSoZ5\nHceYQiUuKpyJfdtQIjSYbQeSqBhbwkb5Np46aYGjqkuBpSLykaqmFGAmU9hkZrBgyi3cWT4CiADg\nu5BH2HXhFQCUf/ghIlu08DBgzlSVN79bz7erdvPFfedbcWPMaYqJCAXgta/X4lPljS5N7SS0xjN5\n+eVVFpGJIrJcRNZlXfyezBQKiSmHeHZobe5MWQNAtagEpq68jP0vvAxAxZdeomzv3l5GzJGq8uKX\nq5m5ajdj72xlZ0w2pySsgtNauay6/W6ye+2mxqSkZ3L3uMWkpGd6HccUU3kpcEYDHwACXAlMBib5\nMZMpJH7d9C1tJ53PJzFRAExuP4Y3h2eQPu1rAOosXECpG2/wMmKu9h9NY9ehFCbe1cbOlGxOnVvX\nZJa03052EaHBvNujOXFR4fz511Gv45hiKi8FTqSqfgOgqn+o6pM4hY4pptIz03ltwWv0nT2AcJ+P\n3lF1+aXiYLi0B+lbthBauTJ1ly8jODpwO+mmZ/oYNvsPoiJCGNK9GbGRoV5HMqZICQ0O4tWbGlOv\nQjQj52zkUJKNl2MKVl4KnFQRCQL+EJG7ReQaIHD/cxm/yvBl0PHTKxm3ehwAU0qcTbftF7G9//2g\nSrn7+1Pru28JCgvcfiwp6Znc8+ESFvy5Hzui1ZwR+/3kyY6DKdzy3jz+SrTTnZiCk5cC50GgJM4p\nGs4D7gJ6+TOUCUyqytMT2rMraTctk1OYdzCG4Dlx/DV0KABn/fA9cffcE9BnA0/P9NF7zCLCQ4MY\n1qM5EaHBXkcyRYAG7k/ecyLCU1fX57L65ekyfC77rMgxBSTXkYxVdb579QhwK4CI2CAHxUyGL4M7\nJ1/Bkoy/aJSSyshmj7J7+hYSZ02hRPPmJIwYTlDJkl7HzJGqEhocxK1tq3FZ/Xg7hNWYAiIiDLi8\nLmdXjqVUZBiqGtAbQqZoyLEFR0Raish1IhLn3m4oImOB+Tk9zhQ9d0/vypLUPcRm+hh763x2jF/F\nwY+nEN2+PdU/+jDgi5t9ianc8O6vbNiTyBUNK1hxY4wHLm9YgeT0TK7+78+s333E6zimiDtpgSMi\nLwMfAd2Br0XkWeAHYBlQp0DSmYAw+5sBzD+4lvppGXzX+E3WNzuXI19/TWilSlT890tex8vVrkMp\ndBkxj/NqxVGrXGAXYsYUdVHhIfS+oAbdRs5nxfZDXscxRVhOu6iuBZqoarKIlAG2Ao1UdWPBRDOe\nU2Xq1B48fWQ5AG/UvJtNdznnXI1o0IDqEycgAdyZOMsjU5ZxU/Mq3G0nAjT5zXqpn5brz6lCidAQ\n7puwlG8euJCwEBsM0OS/nAqcFFVNBlDV/SKyzoqbYkSVWROv4+k05yuf3PI/HL6hPwBx991LuX/9\ny8t0ebLpr6NUiI1gWI/mlAzPtbuZMafNOhmfug5nV+CC2nGEBAlrdx2hbgU7ONfkr5zK5poi8ql7\nmQrUyHb707w8uYh0EJG1IrJBRE54/ioRuVlEVonIShEZfzpvwuQzn4+1Y6/kAbe4mXDlR8SOmQVA\nmV69CkVxs2L7IToPn8vCTfutuCniAmE9k5phRwadjpLhIWzZn0S39+Yxc+Uur+OYIianNf+Nx91+\n51SeWESCgSFAe2AbsFBEpqnqqmzz1AYeB85T1QMiUv5UXsP4x7Nf9OATtgPwXMMBxD47nEPff094\nnTrEP/qIx+lyt3jzfvqMXcyL153NBbXLeR3H+JGtZwq/6nEl+aBnS3qNXkRyeibXNrWDdE3+yOlk\nm7PO8LlbARuydmuJyEScfj2rss1zFzBEVQ+4r7nnDF/TnKHXP76WT5KclpsPLx9Nic73k/jXPoIi\nI6k2dozH6fJm6ZaDDL65Ce3q2v+xYiAg1jO2i+rMNK5Sio96t+bjRVutwDH5xp9t95VxOiZn2Qa0\nPm6eOgAi8gsQDDyrql8f/0Qi0gfoA5CQkOCXsMWd+nw8MqY13wQ5J47/tfmb7O37PKl/7SOyTRsS\nPhgV8ONWfLdqN8FBQu8LanodxZwBd5ytamRbP6nqTyeZPd/WM+48p7SuUetknG/qVojmyasbsHbX\nEeZt3Mft51b3OpIp5LzunBAC1AbaAVWAn0SkkaoezD6Tqo4ARgC0aNHC1ih+8NDEy/g2KIX4VB8f\nHOjOtpvuBaDkhRdQ9d13A764mbZsB89PX8X7t7fwOoo5AyLyKtAFpwUm6zTUCpyswMmLPK1n4PTX\nNbZSyj/RESGM+XUTB5LSuP/S2gG/7jGBK88FjoiEq+qp9KTbDlTNdruKe19224D5qpoO/Cki63BW\nRAtP4XXMGZo5vQ/fpu+l3UYf/Sb5SMQ5z1T5gQMp2/MOb8PlwfRlO3jpy1V82LsV9SrEeB3HnJnr\ngLqnsK7xdj2TrbKx0XnzR6VSJZjUty23vj8fVXiwvQ27Zk5ProMPiEgrEfkdWO/ebiIi/83Dcy8E\naotIDREJA7oC046b5zOcrSrc0ZLrAHYoegFa8uW9PLR/LpUO+ej3sXNf6W7dqLfi90JR3GRk+mhe\nrTQT+7S14qZo2AicyqndA2M9I6DWjpNvykWHM7FPGy5vGI/Pp2T67LM1py4vLThvA1fjrCRQ1WUi\ncnFuD1LVDBG5F/gGZ7/3KFVdKSLPA4tUdZo77XIRyWqOfkRV953mezGnQpVFH11Nz8wt1Nqh/Hti\nMGgG1caNJbJlS6/T5UpVeXvWBnYdTublGxp7HcfknyTgNxGZBRxrxVHV/ieaOZDWM6oK1oCTb0pF\nhlEqMoxRP//Jsm0Heb1zE0KDbUBAk3d5KXCCVHXzcU2vmSebOTtVnQHMOO6+p7NdV2CAezEFaOXH\nt9AzcwtlDyn/Hi9Iejrl7u9faIqbl79aw+y1exnXu5XXcUz+msb/tsDkKFDWM9aC4x/dWifw0/q9\n9PtoCf+95RwiQoO9jmQKibyUw1tFpBWgIhIsIg8A6/ycy/jRlgVDuePo78QfUIaOCUPSM6jw/HPE\n3XOP19Hy5JcN+5i/cR+T+rahfHSE13FMPlLVMcAEYLF7Ge/eF9AUO6LKXyJCgxlxawtCg4WP5m/x\nOo4pRPLSgnMPzm6qBGA38J17nylsVFn12Z10O7SACvuFN97LBJKpNOg1Yq+5xut0ucrI9LFix2HO\nrx1Hqxrn2vlriiARaQeMATbh7PCpKiK353CYuLeyFTXWguM/YSFBvN31HESc0zpULBVBTMSpdNUy\nxVFeCpwMVe3q9yTGvzJSWTMogS6VnMHvXv0hHthB/BNPFIriJjUjk/4TluJTGHFrcytuiq7BwOWq\nuhZAROrgtOg09zTVybgFjlonY78LcfvfTF+2gx/X7WFsr9aUKRn4J/s13snLf4mFIjJDRG4XETsb\nWmGUkYrv35V4rmwsospHn1QibMMO4vr1o8xtt3qdLldJaRn0HrOIIBHe6XaOHYpbtIVmFTcAqrqO\nUzuqqmBlph+7aruoCsZDl9fhwtrl6DJ8LrsPp3gdxwSwXFtwVLWWiJyLc/jlcyLyGzBRVSf6PZ3J\nF76lH3Fn+TKsCA/njW8qELp+K6U630Tcffd6HS1PElMzaFQ5lgHt6xzbijNF1iIRGQl86N7uDizy\nME+Ospc0qj7PchQnIsKjHepROjKMvxJTiY+xfnjmxPL030JVf3UP02wGHAY+8msqkz98PnirKU/N\nf4FFJSJ4YG9TKi/ZhoSGUuGZZwK+JWT/0TSe/nwFsSVCebRDPStuiod7cEYx7u9eVhHIff6yD/S3\n/0/vchRDd11Yk4aVYnnt6zVs2JPodRwTgPIy0F+UiHQXkenAAmAvcK7fk5kz9+1TTE/fzbToKOIO\nKeeOWgJArVnfISFen6UjZ3sOp9Bl+FxKhocQZoVNsaGqqar6H1W9wb28cYojqHsnyA5f9kLNclF0\ne28eq3Yc9jqKCTB5+S+3ApgOvKaqc/ycx+SHzAz4eiDrfxvDE1UqUjq8NO8tSiDdt5jKb75BaPnA\nPsv20dQMbh4+l84tqvKvi8/yOo4pACIyWVVvdkdN/5/OLKoamKM5uklVQMUKHC/c1LwKkWHB3DZq\nPlPuPpfqcSW9jmQCRF4KnJpqO5cLl0/vInnVVAZUqQTAiHL3k77gSUp16UJMhw4eh8tZSnomJcND\n+O8tzWhUJdbrOKbg3O/+vdrTFKfs71rMF2wFjlc6NqpIQplIEspEkpKeaYMBGiCHXVQiMti9+omI\nfHr8pYDymVO1ejqs/JSHqtZkU0gwD5W7BR58nqDoaMo/+IDX6XK0asdhLh08m12HUqy4KWZUdad7\n9S9gq6puBsKBJsAOz4Ll5h8n2/QuhoGzK8eS4VM6vjWHWat3ex3HBICcOjdMcv++Aww5wcUEmg3f\nwaQeDC0Vy5zgdGpEVeP812ehaWlUefstgkuV8jrhSS3ZcoDbRs3n8Y71qBBrR0UUYz8BESJSGZgJ\n3AqM9jRRDjTb3883f+1lFIMzIOB/ujRl4CfLmb4scOtiUzBOWuCo6gL3an1VnZX9AtQvmHgmzw5s\ngsl3MD0qkndLx1IjrCJv/5BA+o4dlH/4IUq2bet1wpNSVV6ZsYZBNzXh6saVvI5jvCWqmgTcAAxV\n1c5AQ48znVy2Vpstidu9y2GOaVq1FB/2bs2QHzZwJCU99weYIisvh6f0OsF9d+Z3EHMG1s2Et5ow\nLyiNJ8rFUTUxnFef20rydz8gkZGU6dnT64QnNW/jPpLSMpnQpw0X1wvszs+mQIiItMUZ/+ZL974A\n7lDhVjgCIUGBfWRicVKvQgwz+l9AZFgIP6zd43Uc45Gc+uB0EZGpQI3j+t98CxwsuIgmRz++AuM7\nkyowsEp1mq33MXiYc1Rt7PXXU3fRQiRAOz9+uXwn945fwpb9SQQHBfaYPKbAPAA8DkxV1ZUiUhP4\nweNMJ+fWN3W2KaFiBU4gCQoSDiSl8dy0lfx31nobaboYymmJXADsA6rwzz43R4Cl/gxl8uijzrB+\nJgBPtriOuN8W89gUH+Cj4ssvU+r667zNl4PJi7by+jdrGdurNfUrxngdxwQIVZ0NzM52eyPOgH8B\nqVLXBmx9fxmV98MqsfGaAk1cVDiT+7alx/vzSUzL4LEO9QJ+gFOTf05a4Kjqn8CfOGcPN4Hmiwdh\n/UwyI0rx2kV3MmvlZIZNCwYyqT5lCiXODtxuCwCZPmVCnzbUKhfldRQTAETkTVV9wB1Q9ETj4HTy\nIFauos4qfex6aFDgnjKrOCsfE8GkPm2ZuHCr11FMATtpgSMis1X1IhE5wD9XOAKoqpbxezpzYlsX\nwqJR7AmPonuts5C5k3ljahDRh9Io/+ijAV3cDPlhA/UqRHNLqwSvo5jAMs79+7qnKU5VtiHCQq0P\nTsAqXTKMe9rVYu2uI4ybt4lnr2lop34pBnL6hi92/8YB5bJdsm4bL6yZAe9fxsawcC6tVIaQzbsZ\nNBbK702nVOebKNsrMDsUqyqvfr2Gz3/bTqPKNsaN+SdVXexeXQTMUdXZ7u6qn4GF3iXLhRU4hUpC\nmUi27E/m3vFLSc3I9DqO8bOcDhPPWnKrAsGqmgm0BfoCNha2F35+EybeggL/V/scau1QXvswiLCU\nTCoNGkTFF17wOuFJDZu9kZ/X/8XEPm0pb2f/NSc3C4jMdrsEAb2b/O/G7RolK3uYw+RFibBg3rut\nOQCPffK7x2mMv+Vlk+MzoKWI1AI+AL4AxlPohlQv5JZPhu+egeAw7mx6KRt3rOC9ycGEpKRRZegQ\noi+5xOuEJ5SR6SM1w8eNzSvTvU0CMRHWT8HkKEJVj50aWlUTRSQypwd4KlsLjh0mXjiEhwTzTrdz\n2HEwhYxMHykZPqLC7bsrivKyE9Knquk4A2/9V1UfBGxTpSDt+A0+vQuAeTcPZ+G+FQyY6iM0OY2K\nL78csMVNWoaP+yYs5b/fb6B8dIQVNyYvjopIs6wbItIcSPYwT87s0ONCKSQ4iISykUxfvoNu783j\nwNE0ryMZP8hLgZMhIp1xhkz/wr3P/lMVlG2LYcRFACy9eSR3zXuGjguVxpuU0t26Beyh4Mlpmdw1\ndhE+VR5sX9vrOKbweAD4WETmiMjPOKeMudfjTCeX/TzEVuwUOtc1rUzbWmXpMmIuew6neB3H5LO8\ntMv1AvoBr6nqRhGpAUzwbywDwNG/YHxnAOZ0eI5+C5/n+l993DLbWamWH/iol+lyNHvdHsqUDGPQ\nTY3taAWTZ6q6UETqAXXdu9a6LciByS1wVleBCv97dLsJcCLCYx3qER0ewqSFW7nvUtsYK0pyLXBU\ndYWI9AfOclc8G1T1Jf9HK+b2/QEfdISkfay/+FH6rx9D2UNK1znOSvSs2bMJCg/3OOT/OpiUxtKt\nB+lwdkWuaFjBBtUyp8TtbzMAqKaqd4lIbRGpq6pf5PZYbyi+6Ez+igmhgtdRzGkREe69pDaqytIt\nB4gtEUpNG5+rSMh101pELgA2AO8Do4B1InKev4MVaxtmwX+bQeIuOLc/jx1aQoYvg6ErWyAINT79\nhND4wDtv054jKXQZPo8Ff+4HsOLGnI4PgDScIzYBtgMvehcnF+5uKeeXbi04hZmIsHHvUbqOmMfq\nnYe9jmPyQV72HbwBdFTV81T1XOAq4C3/xirGdq+Eid2gRBm4dSq/NOzAugPreHHP+cjs+ZTu2oWI\nBg28Tvk/th9MpsvweXRsVJFHr6ib+wOMObFaqvoakA7gnlk8cCtl9QVyOnOKbmxehaeubsCt789n\n2VY75WJhl5c+OGGquirrhqquFpEwP2YqvtJTYGJ3yEiB3rPwxTfg5c86UetoFHXGzCG0UiXiH3/c\n65QnFBESxD3tanFzi6peRzGFW5qIlMBtDnGHp0j1NlIOsncstk7GRcI1TSoRFR5CZFhgnqTY5F1e\nWnCWiMgwETnfvbyLnWwz/x3eAYNqwYE/4eo3oMLZzNw0k/27NvHMmFTIyKTyG/9BQgPrALY1uw5z\n97jFlI4Ms+LG5IdngK+BqiLyEc7Af4Hbm97tZCxW2xQpF9crT+34aJ6dtpIf1uzxOo45TXkpcO4G\nNuKsZB51r/f1Z6hiJyPV6VCclgiXPAUteqGqDF02lLu/gYhDyURf2YESTZp4nfQflm09SI+RC+jY\nuCJBQdZOb86MOJ221uCMuXUHztGaLVT1Rw9j5Ux9WN+boqtT00o8MmUZM37f6XUUcxpy3EUlIo2A\nWsBUd7+48YcZjzgtN81uhwsfBuDVha9y88gNNN+ghFapQpU33vA45D/tS0zlzjELeeWGxlzWIN7r\nOKYIUFUVkRmq2gj40us8eWO7qIqyZgmlGdOrFT0/WEjlUiVoUrWU15HMKThpC46IPIFzmobuwLci\n0qvAUhUn+/6AJWOgSivo9DYAi3cvZsPUcTTfoITEx1Pr6688DvlPe46kUDYqnC/uu8CKG5PflohI\nS69D5Fn2gf6sJadIalgplun3nU/jKrHsOWKDARYmOe2i6g40VtXOQEvgnlN9chHpICJrRWSDiDyW\nw3w3ioiKSItTfY1C79unnb8XDQScs24/NKMfvWY6K85qH32IhATOeVK++n0nV7/9M4eS06kQayfN\nNPmuNTBPRP4QkeUi8ruILM/tQZ6ta7L64OTLk5lAFR8TgSr0/GAhQ3/c4HUck0c5/edMVdWjAKq6\nV0ROaThaEQkGhgDtgW3AQhGZlv2ILHe+aOB+YP4pJS8Kvn8R1nwBZWpC7csAeH3R6/SYdoTSR6HS\n4NcJq1LF45B/+2TxNl79eg0f9GxJbInA6uxsiowrTvUBnq5rVP+ubqwBp0gLChJG3dGSHiPnk5iS\nwSNX1LWxvgJcTkVLTRH51L1MBWplu/1pHp67Fc6oxxtVNQ2YCFx7gvleAF4Filfb35cPwU+DIDgM\nuo4H4MEfHmT2D2M4b7USVrMmsVdd5XHIv6Vn+vhi+Q7G39WGhpVivY5jihgRiRCRB4BHgA7AdlXd\nnHXJ5eHerWsOb3fyK1iFU/TFx0QwqW9bVu08zN7EwB29wDhyasG58bjb75zic1cGtma7vQ2n+fkY\n96zBVVX1SxF55GRPJCJ9gD4ACQkJpxgjAH3cE1Z+CqUS4J65EB7F5LWTmb3xW/4z1WnyThj1vsch\n/zZ50VY6nF2BD3q28jqKKbrG4AzuNwe4EmiA09qSF96ta/ZtALJGFbcCpzgoUzKM0T1bkZHpY9zc\nTdzSKsHOtxegTlrgqOosf76wu8vrPziHg+ZIVUcAIwBatGhRuNciyyY6xQ3AvxZCaASfb/icF+Y+\nz7/HK/EHlHIPDSC0gvdntlFVBs9cx1crdnJRnXLERNhuKeM3DdyjpxCR94EF+fXEBbau8WWeRjpT\nWKVnKjNX7Wbuxn282eUcwkKsyAk0/vxGtgPZR36r4t6XJRo4G/hRRDYBbYBpRbqjceoR+Pxe53qf\nHyE0grX71zJh/BNMfiWTs7b7KNG0KXF33eVlymNe/HI136/Zw+S+bYmPsQ7Fxq+OnTFcVTNO8bGB\nsa5ZOyNfn84EthJhwbx3WwvSM5W+4xaRluHL/UGmQPnz8JyFQG0RqYGzsukKdMuaqKqHgLis2yLy\nI/Cwqi7yYybvpB6BwfXBlw43vg+VziEpPYnHh93IS+OdBSO8Th0Sxo7xOKjTciMitKxemv6X1rYO\nxaYgNBGRrDMcClDCvS04Q+TE5PBYz9c1ojjLuClWIkKDGdq9GV8s30FosBxbd5rAkOcWHBEJP5Un\ndrfC7gW+AVYDk1V1pYg8LyKdTi1mETB3CKQdcQbzO9vp3vTm3EG8NNZp1q4+cQI1p31OUJi3p/lK\ny/DRf+Jv/LRuLx3OrmjFjSkQqhqsqjHuJVpVQ7Jdz6m48X5dk/X/LMjOXVQchQYHcf05Vdi8L4nu\nI+dzMCnN60jGlWsLjoi0At4HYoEEEWkC9FbV+3J7rKrOAGYcd9/TJ5m3XV4CF0qJe50jpuIbHRvM\nb9yqccioSQCUf/RRSjRt6mVCAFLSM+n30RKCRGhVo4zXcYzJs4BY10TY0YXFWbWykTSsFEPXEfMY\nd2drykWfUpuA8YO8tOC8DVwN7ANQ1WXAxf4MVaQk7YcRF4EvAy57BoCUjBQ+nDmI6+YpoXXrUKbn\nHd5mdL08YzVR4SG826MZEaG2NWpMXvhwGnF+j4nLbVZThIkIT3Ssz5VnV6T/BDsfdSDISx+cIFXd\nfNx+RTtcIK8+vt0ZK+PCR6F2exLTEnloaCcGD3f6VFYcONDzfbaHktJRlAGX1yUqPIRgO3GmMXmW\nHORsJw7bNpO+DPI4jfGSiHD/ZbW5Paka6Zk+9hxJpXKpEl7HKrby0oKz1d1NpSIS7A7Gtc7PuYqG\nNV/Cnz9Bo85wyf8B8NqEfjwwbCfBCmXvuZuS557racS9R1LpMmIuU5duJ7ZEqBU3xpwOhRCxVk/j\nKBUZxvyN+7lh6C+s3WWdz72SlwLnHmAAkADsxjnE8pTPS1XsZKbD9AegZDm4+k0Ath3YRJdXFgJO\np+Ly9+d1HDP/2HEwmS4j5nJFwwrccW51T7MYU1hlDZYTcmpnszFF3Pm143iiY326j5zP8m0HvY5T\nLOW6i0pV9+AcdmnyKjMDJnaHo3vg+hEQHsUfq34l7YY7nYqyS6eA6FS8aPMBurasSp8La3kdxZhC\nK9bnQwjmzooXeR3FBJhrm1YmMiyEH9fupXGVUl7HKXbychTVe5xgDHJV7eOXRIVdZjoMOx/2roE6\nV0Ljm0mcPZu0vncDcPDylrR56iVPI67bfYTVOw9zbdPKnuYwpigIclePMcE2GKb5X+0bxNO+QTzz\nNu4jNcPHRXXKeR2p2MhLm+p3wCz38gvOiVfsLGMns2zC38VNt4n4UlPZ+GB/AFY8cCVt3x6LhPhz\nfMWc/b7tEN3em48W7hNeGBMwBGegP5/aSLbm5EKDhQGTfuPrFTu9jlJs5GUX1aTst0VkHPCz3xIV\nZpkZMPNJCC0JnUcDsOHxhwhNSmPytWV5uu9gT+Mt33aQnh8s5N83NOKKht6f68qYoiTTChyTg+bV\nyjCmVyt6jl5Ipg+ualzR60hF3uk0JdQA4vM7SJEw53VIOQTtX4DQCJKXLyfzq+/ZXgba3vO0p4eD\n+3xKtTIlGdq9Ga1rlvUshzFFSmwCkAyA+tJzntcUe2dXjmV879aEBAfh8ylBdtSqX+W6i0pEDojI\nfvdyEPgWeNz/0QqZTb/Ajy9D1dZwXn98KSms6X07ACvva8/l1S/3LNo3K3dxx+iFxJQIseLGmHyl\nx87U4Fs+2dMkpnCoHR9NjbiSPDd9JcNm/+F1nCItxwJHnCaHJkA591JaVWuqqi3J2R3dB6Ovcq5f\n+jS+1FRWn3MOEYdTmHBhEHfc8IJn0T5bup3/m7qCRy6v6/mAgsYUOW5nNlH4LcKG5jd5d3e7Wny8\naCuDZ65FrVOkX+RY4Kjzqc9Q1Uz3Yt/CiXz9GKBw61S02nl8+sC1BCksaVWa/m/NJjbcm3PUbNmX\nxGtfr2H8Xa1pVMXOk2Sq/xIAACAASURBVGNM/lOythu+LRkJBzZ5msYUHhVjSzDp/9u77/ioqvTx\n459nSnojjdCrSOhNBLvIIlbUVRB7Beu667rFr7uu+t2iv7Wsrq6irl8REFRcVyzoomJZpUvvSG9p\nhPRMppzfH/ciISSQ6JRk8rxfr3nl3jtn7nmYkDPPnHvuOZNH8un6fD7fVBDpcKJSY+6iWiEig0Me\nSUt1cBesftNaIbzHKJ556ir6zt/Bdz0TmfB/X5IZH5n1adbvK6VzRgKf/PJMerVNjkgMSkW9ut/5\nnh4YmThUi5SZFMvbt5/CWb2y2LC/FH9A+xCCqcEER0QODUAeDCwRkY0i8q2ILBeRb8MTXgvw6SPW\nzzN/w4IvZ3LOSyvwO2DMjE9wOcN/O7gxhifnbeLumcvx+PwkxETulnSlop99iSrCUaiWKz7GiYjw\n+McbuWfWcrx+vRsvWI7Vg7PY/nkxcCJwPnAFcLn9U23/7/e9N76YHNy//AtiIO2fzxKTGv5ZK40x\n/PGD9cxbl8esSSOIdenaOEqF2qGJ/saVlUc4EtWSPXvVEKpq/Nw2bRnVXl3POhiOleAIgDHmu/oe\nYYqv+aqphLdvBcA35BesPes0Esu8bL1kMB1HnhORkKq8fipr/My6dQSZSTrgUamQsy9RuQOGg07n\n0VO+K9VIcW4nL1w7lE7pCRRV1EQ6nKhwrOsXWSJyb0NPGmOeDEE8LceH90HZXky/Cay+42fEVfn4\nfFQmt/75tbCH4vUH+Nsnm7j19O785bL+Ya9fqdbLSmm8InyREM/7SQlcFOGIVMvldjp46OK+eP0B\nHvtoA7ed0YPUBHekw2qxjtWD4wSSgOQGHq1XeQGsmIFJzGHbv8qJ276fN850MuHJd3E5wjvmpdrr\n5/bp37J+Xxlxbr0kpVRYmSPH4LyXlHj0wGOlmsjlEDzeABNfWkhhua6M9EMd69N4nzHmkbBF0pJM\nvxSAvKJz8Xw7j4MJMOb3U0iPSw9rGMYYJk1bRnKci6fGDyLG1Zib4pRSwWOOGGGc5g/AzoXQZWTk\nQlItnojw+wtzeWreJiZMWcC/7zyV5DjtyWmqYyU4emNAfXYvg/2r8Sb2p3jWPLZnw0cPjubpjqeG\nNQyvP4Db6eDuUT0Z0rkNTp3yW6nIsTttvCLWjQea4KgfSUS4d8yJnNozk6RY1/dtvmq8Y71bkRkp\n25wF/PDunSAOSjOvAuCfY5w8eOpDYQ2jqNzDJc99zbIdxZzUNV2TG6Uipc7lqE8SEyDjhAgFo6LR\nyd0zKCj3MOapL9mcVxbpcFqUBhMcY8yBcAbSInzxGBSsh3P/TP5jf6fGCeddeA8Z8eFb32l/STXj\npyzg7BOzGdI5/LeiK6VqO3oenMIUXSVaBVd2chx3j+rJxJcWsWZPSaTDaTG0v6uxdnxjJThtulKS\neTYA6zsJV/e7Nqxh/OnD9VwxrBP3natrSykVcXYPTociQ+5Oa9tldKI2FXyXDenIHy/pxwPvrCag\nMx43ik5z2xjbvoSp1s2f5szf8t2N1xEPtPndb4hzxYUlhO8KykmNd/PEFQN1MLFSzYXDRfUBF9nA\nwzP8jL/fhQS8kY5KRamx/XI4JzebGn+ADXvKGNRJe/GPRT8pj6fou++TG//oh5n11jvEF5Sx+OQ2\njDn1urCEsGZPCVe+uJBvdxRrcqNUc3L9e0cf+/ft4Y9DtRpup4NthRXc/OoS/rN2f6TDadb00/J4\nlrxs/bzuXZ4s2U+fd1dTlCKc/49/h+US0bIdB7j+lcU8cnFfxvTNCXl9SqkmyO59xG5qhV46UKGX\n2y6F/7vxJP7nnTW8u2JPpMNptjTBORZvNaycCd3PZk96D8564F1ifNDnmZfISswOSwj7Sqp5YvxA\nzuuvAxeVau4uXKzjb1R4DOiYxoxbTia/VCcCbIiOwTmW1W9CVTEMvYGld11Lr2qovvgs0keEfs6b\neevyKCz3MHF455DXpZQKjvI4QacQU+FyYk4yJ+Yk882WQtbvL+Pm07pFOqRmRXtwjmXO3eBOYFGp\nl15L8wAY+MhTIa/23RV7uP9fq+nTLiXkdSmlgqc8Duh6WqTDUK1M18xEZizcwd8+2YTRpUK+pwlO\nQzbPA8B0H8XBhx7F54CM2dNwxIX2rql56/L484frmXHLyQzUEfJKtSjd8gzobeIqzNqnxfPG5JF8\ntGY/L3yxNdLhNBt6iaoh3zwD8el8szGVzjsq2XT5UPr3GxbSKqtq/Izons6bk0fSJSMxpHUppYJv\nzHIDuV9DIAAO/f6owicrOZZZk0ZQ7vFR7fXjdjpa/Sz3If0LFJGxIrJRRLaIyG/ref5eEVknIqtE\n5FMR6RLKeBpt9WzY9iUlXceSPms+FbEw/Df/L2TVGWN45tPN3DNrOclxbk1ulGqCSLczzowjZzI3\nAaBkVzCrUKpR0hJi6NgmgWc/28K9b67A62/dvYkhS3BExAk8B5wH9AEmikifOsWWA8OMMQOA2UDo\nsojGqjwAb98MwIdz1wDgfeAO2iW3D0l1xhgenbuBD1fv44+X9gtJHUpFq+bQzvT4aC7tn3j8+/2S\nzQnw9AB4bkQwq1Gq0e4a1ZOSKi93zPiWaq8/0uFETCh7cIYDW4wxW40xNcAsYFztAsaY+caYSnt3\nIdAxhPE0zn9+B8AHJ17PoIWFbOqXxogr7gpZdWv3lrJk+wFmTRpBdnJ4ZkVWKopEvJ1xJieTesEF\n3+9XLrNvDihYDw+lQuHmYFan1HHFuZ28eO0w3E7h41Y8GWAoE5wOQO1+2t32sYbcDMyt7wkRmSQi\nS0VkaUFBQRBDrKN4O6yYwc5uZ9Hpj9Yg49N//2xIJvTz+QPM35hPvw6pzL7tFNISYoJeh1KtQNDa\nGQhRW7NyJnjKg3MupRopxuXg2YlDGDeoAwu3FlFa3fqWEGkWo+BE5BpgGPDX+p43xrxojBlmjBmW\nlZUVukC+ehKADe/k4/bD3vGnkT5waNCr8fj83DHjW177ZjuBgMHRygeCKRUOx2tnIHhtTcBXa+er\nJ+Avx8q5lAqNQ58tn23I56qXFnKgoibCEYVXKBOcPUCnWvsd7WNHEJHRwAPAxcaYyE3J6PfB8mkU\nmUF02nCQwi5pnPPIS0GvpqrGzy1Tl+J0CFOuHabJjVI/TrNsZyqvXQDxbY48uHIWbPgg1FUrdZT7\nz+vNmb2ymDBlAXml1ZEOJ2xCeZv4EuAEEemG1eBcCVxVu4CIDAamAGONMfkhjOX4lk/DBALs/qKK\nGMD84Z6QVGMwjOieweQzuuNyNosONKVasmbZzuwa91NyN2y3xuAc8s5k6+edSyCrVzjCUAoAEeFX\n5/YmJyWOQCuaCDBkn7DGGB9wF/AxsB540xizVkQeEZGL7WJ/BZKAt0RkhYjMCVU8x7VyJqX7s4nZ\nX8bM8xI5dcQVQT39gYoa7p65HF/AcOfZPTW5USoImlM702vpEjzZVkLjbGuvVXfTxxCffmRBX1Uo\nqlfquK4d2ZW2yXH88s2VbMmP/nFhIf2UNcZ8aIzpZYzpYYz5k33sQWPMHHt7tDGmrTFmkP24+Nhn\nDJH9q2HXIgo2puFzQPW4s3E6nEE7fX5pNROmLKBjm3iSY3VuRaWCqbm0M86kJDY+fRsA/rx8AtXV\n0HkE3LnoyIKLpoSieqUaxeEQRvbIYOJLC1m7tyTS4YSUdiMArHidmjIn3v3lFCfBBT0uDNqpvf4A\nV728iEsGd+A3Y3uH5I4spVTzUO46POfI9ivsXuCkbHjwANxhJzorZsDrEyIQnVKWy4d25OGL+3L9\nK4vJL4veMTnaneAph2+nsWNje8DP9GvaM6XjGUE5dUmll9QENy9fN4yumTo7sVLR7v2t73OKve07\nePDwEw4nZPc+vL/pI9i3CtoNCGt8Sh1yfv929GmXQnZy3PefVdFGe3C+/huBinKqtweY31+4c+KT\nQellWbe3lJ889QVb8ss1uVGqlZg8cDIzzrKaVX/RgaML3LHw8PaU06HkqBu+lAqbrpmJlHt8jH36\nSz5dnxfpcIKudSc4JXvgqydZl98dl89QfeZQBmYN/NGn/XZnMde9sog/XNSXntlJQQhUKdUSuMTF\nuyPtZjUQYH3vXDxba63unJ0Lv6s1geBTdVeVUCq8kmJdPH/NUH7z9ireW7k30uEEVetOcBb+A4yf\nqnWGqhi46oYG5/9qkn9+tY2/Xj6QCwa0C8r5lFItQ4zz6BnJt55/wZEHXDHwq+8O72/6OMRRKXVs\ngzqlMf2Wk5m+cAc1vuhZoLN1JzgbPmCPfwhJRdXs7ZVOTlLOjzrdV5sLyCut5tmrBnN27+wgBamU\nainOaOz4vcRMSO9ubb8+HjxloQtKqUbonZPCrEkj8AcM76+Kjp6c1pvgeKvxFW5j39x8PC7o8ejj\nx3/NMXywah+/eGMFeaXVeqeUUq1Ym9g2jL/fxZ23H55q4t2VM48ueNeyw9t/6XjkpIBKRYCIUFLl\n5fGPN/L3TzdjWvikgK02wTGr3uDV3W1JLA+watIZ5PYc+YPPNXvZbh5+by3Tbj6ZAR3TghilUqql\n+XzC5zw/+nkK0oRCe2HxXhMe4SfTzmRbybbDBR0OuGfVkS9+KBWeGRK+YJWqIyc1jjcnj+S9VXt5\n7KONkQ7nR2mdCY4xfPT5M4xc4CSvUxLX3PX8jzpdeqKbmZNGkNsuJUgBKqVaKoc4OK3Dadw9+G5+\nc+PhXpxn/pTPxe9chK/2SpxtusBDJdaMx4cc+A72Lg9jxEodKTsljjcmjWzxN8m0zgRnycvkLa7A\nAQx57Hkcjqa/DcYYnv1sMzMX72RU77b0yGrZ/xGUUsE1acAkpk1894hjly4wDJ42+OjCnUdYic45\nf7D2XzzL6s15KNVapFOpMGuTGMPlQzuyaGsRv569Ep+/5Q0+bn0Jjq+G/Z89TLftQn5uW1KGDGvy\nKYwxPPbRRuas3Ms5OphYKdWAHmk9yN2wnvgh1mWnK76yPiT6T+1P/6n9CZgAJZ6Sw706J91y9Ene\nmWwlOhvnHj5mjDVRYKDlfeiolmVAxzTySj3c9fpyPD7/8V/QjLS+mYwX/oOPPA5OLoHAVaN/0Cmm\nL9rJ11sKeWPSSNokHn1bqFJK1db19Rms752LKwCJVYaKeOtGhIGv1TPvVrfOvHLuK+Qk5JDz95Nx\neysA8M+8kgZXyLtxLnQ5paFnlfrB4mOcvHjdUO6ZuYI/vr+e/72kX6RDarTWl+B89xmFu5IAQ89L\nrm3SS33+AAervPx0SAfGDWpPSlz0TW2tlAqt//ubn/cfvYA3Cj7CE1P/HZc3fXyTtdExA0w6zgD4\nnVbZ1dt21nPS845dac+fwAk/gZNutQY3K9UEsS4nz141mJIqLxUeHwFjSG4Bn3+tK8E5sI2Vexcw\neF0mVTlpxHbp0uiXenx+fj5rBW0SY/jzpf1DGKRSKhp1f/89tl54EQAX/vYD6i7p2+GZp8lbvoDJ\ncW9x/5t+OhYdfY7CZDjlnt58c429cKe3Cl44DYq2HLvyLfOsx9xfW/s9R0NcGvQ6F9oPAVcsuBPA\n6YLYFNCpLlQdLqeDjKRYpn6znbe/3c3UG4c3+ysY0tLucx82bJhZunTpD3vx86dyr28/10+JIWnI\nUHq8Nr1RL6uq8XPb9GXEuR08M3Ewsa4GO4qVatVEZJkxpukD25qhH9XWNKDim2/YedPNQTnX26cI\n2SWQVAUd0ruSHtuGbnfdh1MEv6ca14C+bC3fgclbQ25VBY4P7m38yc9/3BoPpImOqsMYw6MfbWD+\nhnym33wy2SlxYY+hse1M6+nBKdzCzqINuPbnEOMLkHXt9Y1+6Zq9JbRNieXPl/bH5dTuXaXUD5N4\nyin0XrcWU1UFTif+oiL8FRVsu3jcEeVSL7uMnN//DomNRexLSr6iIjbefD2ODdYyDz/9ptaX063b\ngG3s+vqqI84j9uO2cQ4W5HaiY3Inbus8lgtNPM59q2DngsO9Pzn9Yf9qa/vD+6xH3bMNuhq6nQG9\nL4BYvXO0NRIRfju2N8mxLuZvzGfCSZ0jHVKDWk8Pzrw/8OKqVzj5lSRis9vSe/7nx31JcUUN89bn\nMX5Yp6bXp1QrpD044VE45UUO/utfJI0ZzaaYYqbve48LFnrptRe+zhVOXX/8dn1tZyhNEGaf6mBv\nhjXG554h93B9xjDc0y6BquKmB9blNMjqZV3mSsyE1E7QYxTE6Rxh0Wreujx6ZCXSPYxTpWgPTm0B\nP6x6k/2704jx+0jse/xR4Pll1Vz78mLOOjELY4wuv6CUajYyJ08ic/IkAHKAM/jT98/l1ilbsXAR\ne351H/6CwiOO990JYBi5ofatv0+wBVjRLQGfM4GMMoirMSR4HaRUBPjiJ8lkdE4kMyeeEQW7oHQX\nsYnZOMvzrJfv+K/1aEhyO4hJtH7GpkBaZ2s/9yJIzrEeqkUprqxh4kurefXG4c1ustvWkeAsn85G\nTwE9N1pz1nR44oljFs8rrebKFxdy6eAO3D2qpyY3SqkWK3HEyfT66qujjpd98gkVCxdR/tln+IqL\nrctmtkHb6vYAWfPtnPWfMsBaGHQHsLldO9Z3Fnzx3XAYoWBUX8b0PINOsSk4SvcRW7CRNivfoE0g\nAPHpUFkEZfuOHhT9Vd21AMXqAep4EpTnQf566DDUGhTd9XSIS4U2XXWMUDMwflgn4t1Orv3nIl69\ncTj9OjSfNdWi/xKVMfBIOq+5MjhpmpvA6FPp++zLxyhu8PgCfLI+jwsHtA9CxEq1HnqJquUzfj/+\n0lIcsbHgciFuNyJC4XfrOPD+HGpmz8FZ0LTLV8t6Chs6CgGBzwcI4nTicrjwxzhJdjjIwkmn6nIy\nKg7S0eejn8dDaiCAR4QUf4A4Y/CJUCNCAKgRwS+Q4g+QnnECUl1qJUBxqVbvUOcR1l1icamQlG39\n1GQopL7cVEDvdslkJcWGvFOgse1M9Cc4u5fhfXkUT+/pwgVfeek8fRqJw+p/XzbsL+XBf69l2i3D\n9U4ppX4ATXBaF39ZGf4DB6jZtZu9Tz1OYaoQW1CKx1NBm50Hm3y+wmQ4kAzFSYIRqIqB1AooS4Bd\nWUJxEsT4oNoNfgc4A1AZC4UpQsABPrfhQKLgdQIiXFJWTqbfj8NYSVFqIEBmUjvicZIQm0xy8S78\n3c8k0Z2Ey1NOfNczSIhNIjYhk/j0E5DETCswTY4a7bZpy5hwUifODuEs/zoG55CF/+CL+HjOWeil\nJie9weRmxa6D3DJ1CQ9e1FeTG6WUagRncjLO5GRiunSh12mn0queMsYY/MXF1OzYQfXqNVQuXYoz\nNQXv3n34CgsxHg8127cDkFlmPaC+L94/5Mu4dQuzxwVbc8DrEvaklANQEVdCSqVQtvRLyhIEpx+c\ngS/xuIUDyZBYDWXxUJoAZQlCPH7yEpwcSIIYgRNrvCQ6Ymgfl0FGVQllMYm4k9rSLi4dvFV4RWif\n1Y+k5PYkxqbRPqUzWYntkPhUcLhAHFGZOE06szuTXlvKI+P6cX7/dhGNJboTnIAftsxj0bYMLvMG\naHPdDfUWq/D4uGP6Mh69bACj+7QNb4xKKRXFRARXejqu9HQSBg8m/brjzyD//ZWFQADj8eDNyyNQ\nWorxBzBeL+J04CssxJmaSuWyb3G1zcZ4aqheu5aanTvxHzyIIymRml27CRQXE5/Tjtz9+eDzNVRj\nA9t1+QlwaBFHBwcTfcR486iIg7L4airjDuB1Qo0LyhKhsmApX/dw4HdYSVZpApTHQyAhQGGME0cA\nMtw+xGnYFx9D2wB4HA7icZDkcNHJnYbHFUOKuEiPbUN8XCpx8RmkxaaRkphNSkIW6fEZuJPbEXC4\ncDtjSHInRXTc6JDObZh603BuenUJvXOSw3p3VV3RneBs+ZRFxV4u+yJARUYCvW88eiG77YUVdM1M\nZO7PzyA1vvlPPa2UUtHu+w9opxNJSCC2W7cGyyaOHNno8xqfD0QwXi/G47FmbsZgvF7w+8EYAlVV\nBCoq8BUWIW43gapKarZuw19SAg7Bu3cvFQsWEHdCL1i8GGdWJonFxbRNySSQXwieGnA6wWslU713\nN7Qg6qG71w7NVmSVP5xAAZSzPRuSq6xLcSmVEBDYkS3siAUxkFli2NxBSPBAdQykl8F37YSyePDH\nBiiJcZDlgMqEAP7YBPLjDblJbTjohAFx2RQ4DFkJ2XRP7oIr4Cc7rQeuhHSSk9uTnNSOOHc8LnE1\nKWnq2z6V//ziTFLj3WwrrKBbZmKjXxtM0Z3gFKwnb0MyKUD3vz171C9o7up9/P7dNXzws9NpG4HZ\nGJVSSoWPuKyPPHE6Ia4Jbf7ZZze5LhMIYGpqCJSV4SsowLs/j0BlJf7SEvD5CFR7CJSVITExeDZt\nxF9SisTEULNrJ6bGi8S4cSQkcqIIAePHu34jAIG0BAYU+XGUer6vq3u+wVErjzppc+1eqNoJVqX9\n89Adc3upjIE4r5Uc5afCLgM+J+SnCWLA47YeBalCYrWhKEWI8UGaV6hKddAON4HMZHwYurbthDs2\nFomPIzYpC09sDG8uqeLkbl0ZP3wAKUntkOS24AxPZ0JUJzjV6+bTaauT9f1TyT3pyCx/9rLdPPbR\nBqbeNFyTG6WUUkElDgcSF4cjLg5XVhZxffqEpd5ARQX+8nL8Bw7gLyvDl5dPoKKCQGUlpsYDDieB\n0hI8O7cT8NXgOlhEjdMQ668mJ+8ArqIKAkluemyoqnNmU+cnWL1QXg4nTvlHxfNLrEt2G9xWL9TB\nRKhxCwGnoTJBqEp14kqNJa1NG04Z93M6978gaO9F9CY4gQBb5m4kzgty9aVHPGWMYdHWImbeOoKe\n2TrduFJKqejgSEzEkZiIu23wxpMarxfj82E8Hozfb/VMVVYSqKzEu38/NcVFePBSU11GZeE+MD7M\nnn14pIZAYQnlBwvxllURH+Mmq9xDwoEAsdXgMAbr0pwPqGBX0nua4DRK2V4OHPSThZPTzz28uN20\nBdsZlduWv14xMHKxKaWUUi2EuN2I2w3x8Uc9F9+/f6PPU+7xMfWb7Uw+ozsupwPj8+EvLcV/sISi\nrWvp2KdvMMMmaleOrFn+MRl7nawZkUFmfCbGGP768QamLtiBMwpvzVNKKaWaM4fAwq1F/GzWcmp8\nAcTlwpWeTmz3brQffSHJ7RseTP6D6gvq2ZqRb+e+hQNwnGcNDnt07gY+31jAG5NGkJOqY26UUkqp\ncEqIcfHy9cPw+Q23TV9GIBDaiYaj9hLVvs27ccfA2EvuxxjDObltuePsnnoruFJKKRUhsS4nz109\nhG++K8LhEAIBg8MRmqsqIe3BEZGxIrJRRLaIyG/reT5WRN6wn18kIl2DVXfafj9FHWP59ewN/HvF\nHoZ3S9fkRqkoFcm2RinVNG6ngzN7ZbFq90Euf+EbDlbWhKSekCU4IuIEngPOA/oAE0Wk7n1yNwPF\nxpiewFPAY8Gou7R4D1nFUNgmEY8vwHn9IjtdtFIqdCLZ1iilfrj+HVIZ2qUNV764kIIyz/Ff0ESh\n7MEZDmwxxmw1xtQAs4BxdcqMA6ba27OBcyQIc0wXLv4Ep4HKjAyev2YIcW5dW0qpKBaxtkYp9cOJ\nCP9zfi7n9WvHg++uCfr5QzkGpwOwq9b+buDkhsoYY3wiUgJkAIW1C4nIJGASQOfOnY9bcXL3XNad\n14HTb7oVtzNqx1ErpSwRa2uUUj+OiHDP6BOo9vqPX7iJWsSnvzHmRWPMMGPMsKysrOOWzzphOBc+\n9Qkn9r8oDNEppaJFU9sapVRwhOJKSygTnD1Ap1r7He1j9ZYREReQChSFMCalVPTRtkYpdZRQJjhL\ngBNEpJuIxABXAnPqlJkDXG9vXw58ZowJ7Y3xSqloo22NUuooIRuDY1/nvgv4GHACrxhj1orII8BS\nY8wc4J/ANBHZAhzAapiUUqrRtK1RStUnpBP9GWM+BD6sc+zBWtvVwBWhjEEpFf20rVFK1dUiBhkr\npZRSSjWFJjhKKaWUijqa4CillFIq6miCo5RSSqmoIy3tTkkRKQB2NLJ4JnVmKm2mNM7g0jiDqylx\ndjHGRMUMeU1oa6Lx9xhJGmfwtZRYGxtno9qZFpfgNIWILDXGDIt0HMejcQaXxhlcLSXOSGkp74/G\nGVwtJU5oObEGO069RKWUUkqpqKMJjlJKKaWiTrQnOC9GOoBG0jiDS+MMrpYSZ6S0lPdH4wyulhIn\ntJxYgxpnVI/BUUoppVTrFO09OEoppZRqhTTBUUoppVTUafEJjoiMFZGNIrJFRH5bz/OxIvKG/fwi\nEeka/igbFee9IrJORFaJyKci0qU5xlmr3E9FxIhIxG49bEysIjLefl/Xisjr4Y7RjuF4v/vOIjJf\nRJbbv//zIxDjKyKSLyJrGnheROQZ+9+wSkSGhDvGSNO2Jrxx1ioX0bZG25mgxxm+tsYY02IfgBP4\nDugOxAArgT51ytwBvGBvXwm80UzjPBtIsLdvb65x2uWSgS+BhcCwZvy7PwFYDrSx97ObaZwvArfb\n232A7RGI8wxgCLCmgefPB+YCAowAFkXi9x6ph7Y14Y/TLhfRtkbbmZDEGra2pqX34AwHthhjthpj\naoBZwLg6ZcYBU+3t2cA5IiJhjBEaEacxZr4xptLeXQh0DHOM0Lj3E+B/gceA6nAGV0djYr0VeM4Y\nUwxgjMkPc4zQuDgNkGJvpwJ7wxifFYAxXwIHjlFkHPCasSwE0kSkXXiiaxa0rQmultLWaDsTZOFs\na1p6gtMB2FVrf7d9rN4yxhgfUAJkhCW6emKw1RdnbTdjZbDhdtw47e7CTsaYD8IZWD0a8572AnqJ\nyNcislBExoYtusMaE+dDwDUishv4ELg7PKE1SVP/D0cbbWuCq6W0NdrOhF/Q2hpXUMJRQSMi1wDD\ngDMjHUtdIuIAngRuiHAojeXC6j4+C+tb6pci0t8YczCiUR1tIvCqMeYJERkJTBORfsaYQKQDU9FL\n25qg0XammWrpt3cblAAABpRJREFUPTh7gE619jvax+otIyIurK65orBEV08MtvriRERGAw8AFxtj\nPGGKrbbjxZkM9AM+F5HtWNdH50Ro8F9j3tPdwBxjjNcYsw3YhNUQhVNj4rwZeBPAGLMAiMNadK45\nadT/4SimbU1wtZS2RtuZ8AteWxOJQUZBHKzkArYC3Tg8sKpvnTJ3cuTAvzebaZyDsQaJndCc3886\n5T8ncoOMG/OejgWm2tuZWN2eGc0wzrnADfZ2Lta1cYnAe9qVhgf+XcCRA/8WR+L3HqmHtjXhj7NO\n+Yi0NdrOhCzesLQ1Yf+HheCNOh8rY/4OeMA+9gjWNxOwstS3gC3AYqB7M43zEyAPWGE/5jTHOOuU\njUij04T3VLC6udcBq4Erm2mcfYCv7UZpBTAmAjHOBPYBXqxvpDcDtwG31Xovn7P/Dasj+Xtvxv/f\ntK0JYpx1ykasrdF2Juhxhq2t0aUalFJKKRV1WvoYHKWUUkqpo2iCo5RSSqmoowmOUkoppaKOJjhK\nKaWUijqa4CillFIq6miCEyVExC8iK2o9uh6jbNeGVnJtYp2f26vXrrSnKT/xB5zjNhG5zt6+QUTa\n13ruZRHpE+Q4l4jIoEa85ucikvBj61ZKBU+tdm6NiLwnImlBPv8NIvKsvf2QiNwXzPOr8NIEJ3pU\nGWMG1XpsD1O9VxtjBmItMvjXpr7YGPOCMeY1e/cGoH2t524xxqwLSpSH4/wHjYvz54AmOEo1L4fa\nuX5YCzbeGemAVPOlCU4Us3tqvhKRb+3HKfWU6Ssii+1vRatE5AT7+DW1jk8REedxqvsS6Gm/9hwR\nWS4iq0XkFRGJtY8/KiLr7Hoet489JCL3icjlWOvizLDrjLd7XobZvTzfJyV1vmU1Nc4F1Fq4TUSe\nF5GlIrJWRB62j/0MK9GaLyLz7WNjRGSB/T6+JSJJx6lHKRVadf+Wf2X30K469LdsH7/OPrZSRKbZ\nxy4SkUV2O/WJiLSNQPwqxDTBiR7xtS5PvWMfywd+YowZAkwAnqnndbcBTxtjBmElGLtFJNcuf6p9\n3A9cfZz6LwJWi0gc8CowwRjTH2sK8dtFJAO4FGv68AHAH2u/2BgzG1iK1dMyyBhTVevpt+3XHjIB\nmPUD4xwL/LvW/gPGmGHAAOBMERlgjHkGaxrzs40xZ4tIJvA7YLT9Xi4F7j1OPUqpELG/yJwDzLH3\nx2Ct/zQcGAQMFZEzRKQv1t/uKLsH9x77FP8FRhhjBgOzgF+H+Z+gwkBXE48eVfaHfG1u4Fl7zIkf\n6FXP6xYAD4hIR+BfxpjNInIOMBRYIiIA8VjJUn1miEgVsB24GzgR2GaM2WQ/PxWrG/lZoBr4p4i8\nD7zf2H+YMaZARLaKyAhgM9Aba8rxO5sYZwyQhNUAHjJeRCZh/S20w5rOfFWd146wj39t1xOD9b4p\npcIrXkRWYPXcrAfm2cfH2I/l9n4SVsIzEHjLGFMIYIw5YD/fEXhDRNph/T1vC0/4Kpw0wYluv8Ba\nc2YgVm9ddd0CxpjXRWQR1gJnH4rIZKy1QKYaY+5vRB1XG2OWHtoRkfT6ChljfCIyHOtb1+XAXcCo\nJvxbZgHjgQ3AO8YYI1a20eg4gWVY42/+DlwmIt2A+4CTjDHFIvIq1npCdQkwzxgzsQnxKqWCr8oY\nM8i+AeBjrC85z2D9jf7FGDOldmERubuB8/wdeNIYM0dEzgIeCl3IKlL0ElV0SwX2GWMCwLXAUeNT\nRKQ7sNW+LPMu1qWaT4HLRSTbLpMuIl0aWedGoKuI9LT3rwW+sMespBpjPsRKvAbW89oyILmB874D\njAMmYiU7NDVOYy289ntghIj0BlKACqDEvgZ/XgOxLAROPfRvEpFEEamvN0wpFQbGmErgZ8AvRcSF\nlezcdGhsnIh0sNuFz4Ar7Evktb+ApQJ77O3rwxq8ChtNcKLbP4DrRWQl1mWdinrKjAfW2N2+/YDX\n7DuXfgf8R0RWYXUDt2tMhcaYauBG4C0RWQ0EgBewkoX37fP9l/rHsLwKvHBokHGd8xZjdUl3McYs\nto81OU57bM8TwK+MMSuxurQ3AK9jXfY65EXgIxGZb4wpwLrDa6ZdzwKs91MpFSHGmOVYl5MnGmP+\ng/U3vMBud2YDycaYtcCfsL5krcRa9RusHpu3RGQZUBj24FVY6GriSimllIo62oOjlFJKqaijCY5S\nSimloo4mOEoppZSKOprgKKWUUirqaIKjlFJKqaijCY5SSimloo4mOEoppZSKOv8fSKuNDKq42R0A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8a0d62e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax21 = fig.add_subplot(1, 2, 1)\n",
    "ax22 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "neutral_line = np.linspace(0, 1, 10)\n",
    "ax21.plot(neutral_line, neutral_line, lw=1, ls='--')\n",
    "ax22.plot(neutral_line, 1- neutral_line, lw=1, ls='--')\n",
    "\n",
    "ginis_xgb = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    rstate = None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rstate)\n",
    "\n",
    "    num_class1 = np.sum(y_train)\n",
    "    num_class1_to_resample = 2 * num_class1\n",
    "    num_class0_to_resample = int(1 * num_class1_to_resample)\n",
    "\n",
    "    # First, randomly undersample the majority\n",
    "    rus = RandomUnderSampler(ratio={0: num_class0_to_resample , 1: num_class1})\n",
    "    X_tlrus, y_tlrus = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "    # Then use SMOTE to oversample the minority\n",
    "    smote = SMOTE(ratio={0: num_class0_to_resample , 1: num_class1_to_resample}, n_jobs=8)\n",
    "    X_res, y_res = smote.fit_sample(X_tlrus, y_tlrus)\n",
    "\n",
    "    # GradientBoost\n",
    "    clf = best_xgb\n",
    "    clf.fit(X_res, y_res)\n",
    "\n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    y_proba2 = clf.predict_proba(X_test)\n",
    "    ginis_xgb.append(my_gini(y_test, y_proba2))\n",
    "    report2 = classification_report(y_test, y_pred2, digits=4,\n",
    "                                   labels=None, target_names=None)\n",
    "\n",
    "    precision2, recall2, _ = precision_recall_curve(y_test, y_proba2[:, 1], pos_label=1)\n",
    "    fpr2, tpr2, _ = roc_curve(y_test, y_proba2[:, 1], pos_label=1)\n",
    "    ax21.plot(fpr2, tpr2)\n",
    "    ax21.set_xlabel('False Positive Rate')\n",
    "    ax21.set_ylabel('True Positive Rate')\n",
    "    ax21.set_title('GradientBoost ROC')\n",
    "    ax22.plot(recall2, precision2)\n",
    "    ax22.set_xlabel('Recall')\n",
    "    ax22.set_ylabel('Precision')\n",
    "    ax22.set_title('GradientBoost Precision-Recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Gini=%.3f+/-%.3f, Best=%.3f' % (np.mean(ginis_xgb), np.std(ginis_xgb), np.max(ginis_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
