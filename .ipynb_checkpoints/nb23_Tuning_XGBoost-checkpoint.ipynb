{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import feature_processing as fp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gini(y_true, y_probas):\n",
    "    auc = roc_auc_score(y_true, y_probas[:, 1])\n",
    "    gini = 2*auc - 1\n",
    "    return gini\n",
    "\n",
    "gini_scorer = make_scorer(my_gini, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/trainset_digitized.csv')\n",
    "feature_space = pd.read_csv('./data/rfe_features.csv')\n",
    "target = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature_space)\n",
    "y = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595212, 108), (595212,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate = None\n",
    "\n",
    "# Set targets for the number of each class\n",
    "num_class1 = np.sum(y)\n",
    "num_class1_to_resample = 2 * num_class1\n",
    "num_class0_to_resample = int(1 * num_class1_to_resample)\n",
    "\n",
    "# First, randomly undersample the majority\n",
    "rus = RandomUnderSampler(ratio={0: num_class0_to_resample , 1: num_class1})\n",
    "X_tlrus, y_tlrus = rus.fit_sample(X, y)\n",
    "\n",
    "# Then use SMOTE to oversample the minority\n",
    "smote = SMOTE(ratio={0: num_class0_to_resample , 1: num_class1_to_resample}, n_jobs=4)\n",
    "X_res, y_res = smote.fit_sample(X_tlrus, y_tlrus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "[CV] gamma=0 .........................................................\n",
      "[CV] ................ gamma=0, score=0.2575470194146465, total=   5.9s\n",
      "[CV] gamma=0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... gamma=0, score=0.27580596305669136, total=   8.1s\n",
      "[CV] gamma=0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ gamma=0, score=0.9996698890420066, total=   7.7s\n",
      "[CV] gamma=0 .........................................................\n",
      "[CV] ................ gamma=0, score=0.9995916109286411, total=   6.0s\n",
      "[CV] gamma=0.5 .......................................................\n",
      "[CV] ............. gamma=0.5, score=0.25714472430716184, total=   6.0s\n",
      "[CV] gamma=0.5 .......................................................\n",
      "[CV] ............. gamma=0.5, score=0.27600071492310363, total=   5.8s\n",
      "[CV] gamma=0.5 .......................................................\n",
      "[CV] .............. gamma=0.5, score=0.9996383058205878, total=   5.5s\n",
      "[CV] gamma=0.5 .......................................................\n",
      "[CV] ............... gamma=0.5, score=0.999602557965559, total=   5.5s\n",
      "[CV] gamma=1 .........................................................\n",
      "[CV] ............... gamma=1, score=0.25797098761540793, total=   5.9s\n",
      "[CV] gamma=1 .........................................................\n",
      "[CV] ................ gamma=1, score=0.2798129610350335, total=   5.8s\n",
      "[CV] gamma=1 .........................................................\n",
      "[CV] ................ gamma=1, score=0.9996076405184138, total=   5.5s\n",
      "[CV] gamma=1 .........................................................\n",
      "[CV] ................ gamma=1, score=0.9996584575477094, total=   5.5s\n",
      "[CV] gamma=2 .........................................................\n",
      "[CV] ................. gamma=2, score=0.254492167169855, total=   5.8s\n",
      "[CV] gamma=2 .........................................................\n",
      "[CV] ................ gamma=2, score=0.2785237604543882, total=   5.8s\n",
      "[CV] gamma=2 .........................................................\n",
      "[CV] ................ gamma=2, score=0.9996727447907681, total=   5.5s\n",
      "[CV] gamma=2 .........................................................\n",
      "[CV] ................ gamma=2, score=0.9996396147054369, total=   5.5s\n",
      "[CV] gamma=4 .........................................................\n",
      "[CV] ................ gamma=4, score=0.2611252811117062, total=   5.8s\n",
      "[CV] gamma=4 .........................................................\n",
      "[CV] ................ gamma=4, score=0.2848895219169749, total=   5.9s\n",
      "[CV] gamma=4 .........................................................\n",
      "[CV] ................ gamma=4, score=0.9996521935987897, total=   5.6s\n",
      "[CV] gamma=4 .........................................................\n",
      "[CV] ................ gamma=4, score=0.9996212223235341, total=   5.5s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] ................ gamma=8, score=0.2693893335692952, total=   5.8s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] ................ gamma=8, score=0.2899026613785112, total=   5.8s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] ................ gamma=8, score=0.9994433839691301, total=   5.5s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] ................ gamma=8, score=0.9995153216403054, total=   5.5s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ............... gamma=16, score=0.2679193198959533, total=   5.8s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] .............. gamma=16, score=0.28559908199236306, total=   5.8s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ............... gamma=16, score=0.9992278939271899, total=   5.5s\n",
      "[CV] gamma=16 ........................................................\n",
      "[CV] ................ gamma=16, score=0.999096733466228, total=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 1s, sys: 214 ms, total: 23min 1s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[0, 0.5, 1, 2, 4, 8, 16]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=3, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.861787</td>\n",
       "      <td>0.064373</td>\n",
       "      <td>0.633154</td>\n",
       "      <td>0.793506</td>\n",
       "      <td>0</td>\n",
       "      <td>{'gamma': 0}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.257547</td>\n",
       "      <td>0.878112</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.874609</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.708359</td>\n",
       "      <td>0.965504</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.366534</td>\n",
       "      <td>0.082880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.663514</td>\n",
       "      <td>0.051342</td>\n",
       "      <td>0.633097</td>\n",
       "      <td>0.793963</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.879770</td>\n",
       "      <td>0.276001</td>\n",
       "      <td>0.874281</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.710105</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.711697</td>\n",
       "      <td>0.207626</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.083087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.619513</td>\n",
       "      <td>0.051347</td>\n",
       "      <td>0.634263</td>\n",
       "      <td>0.791969</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gamma': 1}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.257971</td>\n",
       "      <td>0.876687</td>\n",
       "      <td>0.279813</td>\n",
       "      <td>0.873878</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.711075</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.706237</td>\n",
       "      <td>0.166035</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.365452</td>\n",
       "      <td>0.083337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.611985</td>\n",
       "      <td>0.050539</td>\n",
       "      <td>0.633082</td>\n",
       "      <td>0.783109</td>\n",
       "      <td>2</td>\n",
       "      <td>{'gamma': 2}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.254492</td>\n",
       "      <td>0.871711</td>\n",
       "      <td>0.278524</td>\n",
       "      <td>0.867228</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>0.698067</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.695432</td>\n",
       "      <td>0.143704</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.366673</td>\n",
       "      <td>0.086380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.645984</td>\n",
       "      <td>0.049304</td>\n",
       "      <td>0.636322</td>\n",
       "      <td>0.745044</td>\n",
       "      <td>4</td>\n",
       "      <td>{'gamma': 4}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.261125</td>\n",
       "      <td>0.842952</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.838528</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>0.649470</td>\n",
       "      <td>0.160508</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.363412</td>\n",
       "      <td>0.095709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.614436</td>\n",
       "      <td>0.043096</td>\n",
       "      <td>0.639563</td>\n",
       "      <td>0.686913</td>\n",
       "      <td>8</td>\n",
       "      <td>{'gamma': 8}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269389</td>\n",
       "      <td>0.797045</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.794539</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.576554</td>\n",
       "      <td>0.146695</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.359990</td>\n",
       "      <td>0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.626797</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.637961</td>\n",
       "      <td>0.659012</td>\n",
       "      <td>16</td>\n",
       "      <td>{'gamma': 16}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.776696</td>\n",
       "      <td>0.285599</td>\n",
       "      <td>0.774978</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.543313</td>\n",
       "      <td>0.999097</td>\n",
       "      <td>0.541060</td>\n",
       "      <td>0.148648</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.361256</td>\n",
       "      <td>0.116829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       6.861787         0.064373         0.633154          0.793506   \n",
       "1       5.663514         0.051342         0.633097          0.793963   \n",
       "2       5.619513         0.051347         0.634263          0.791969   \n",
       "3       5.611985         0.050539         0.633082          0.783109   \n",
       "4       5.645984         0.049304         0.636322          0.745044   \n",
       "5       5.614436         0.043096         0.639563          0.686913   \n",
       "6       5.626797         0.036721         0.637961          0.659012   \n",
       "\n",
       "  param_gamma          params  rank_test_score  split0_test_score  \\\n",
       "0           0    {'gamma': 0}                5           0.257547   \n",
       "1         0.5  {'gamma': 0.5}                6           0.257145   \n",
       "2           1    {'gamma': 1}                4           0.257971   \n",
       "3           2    {'gamma': 2}                7           0.254492   \n",
       "4           4    {'gamma': 4}                3           0.261125   \n",
       "5           8    {'gamma': 8}                1           0.269389   \n",
       "6          16   {'gamma': 16}                2           0.267919   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.878112           0.275806            0.874609   \n",
       "1            0.879770           0.276001            0.874281   \n",
       "2            0.876687           0.279813            0.873878   \n",
       "3            0.871711           0.278524            0.867228   \n",
       "4            0.842952           0.284890            0.838528   \n",
       "5            0.797045           0.289903            0.794539   \n",
       "6            0.776696           0.285599            0.774978   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999670            0.712943           0.999592   \n",
       "1           0.999638            0.710105           0.999603   \n",
       "2           0.999608            0.711075           0.999658   \n",
       "3           0.999673            0.698067           0.999640   \n",
       "4           0.999652            0.649225           0.999621   \n",
       "5           0.999443            0.579512           0.999515   \n",
       "6           0.999228            0.543313           0.999097   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.708359      0.965504        0.019599        0.366534   \n",
       "1            0.711697      0.207626        0.002027        0.366584   \n",
       "2            0.706237      0.166035        0.001378        0.365452   \n",
       "3            0.695432      0.143704        0.001247        0.366673   \n",
       "4            0.649470      0.160508        0.000894        0.363412   \n",
       "5            0.576554      0.146695        0.002145        0.359990   \n",
       "6            0.541060      0.148648        0.002262        0.361256   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.082880  \n",
       "1         0.083087  \n",
       "2         0.083337  \n",
       "3         0.086380  \n",
       "4         0.095709  \n",
       "5         0.108888  \n",
       "6         0.116829  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "[CV] gamma=7 .........................................................\n",
      "[CV] .......................................... gamma=7, total=   6.0s\n",
      "[CV] gamma=7 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... gamma=7, total=   5.8s\n",
      "[CV] gamma=7 .........................................................\n",
      "[CV] .......................................... gamma=7, total=   5.6s\n",
      "[CV] gamma=7 .........................................................\n",
      "[CV] .......................................... gamma=7, total=   5.5s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] .......................................... gamma=8, total=   5.8s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] .......................................... gamma=8, total=   5.8s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] .......................................... gamma=8, total=   5.5s\n",
      "[CV] gamma=8 .........................................................\n",
      "[CV] .......................................... gamma=8, total=   5.5s\n",
      "[CV] gamma=9 .........................................................\n",
      "[CV] .......................................... gamma=9, total=   5.8s\n",
      "[CV] gamma=9 .........................................................\n",
      "[CV] .......................................... gamma=9, total=   5.8s\n",
      "[CV] gamma=9 .........................................................\n",
      "[CV] .......................................... gamma=9, total=   5.5s\n",
      "[CV] gamma=9 .........................................................\n",
      "[CV] .......................................... gamma=9, total=   5.5s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   5.9s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   5.9s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   5.5s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   5.5s\n",
      "[CV] gamma=11 ........................................................\n",
      "[CV] ......................................... gamma=11, total=   6.5s\n",
      "[CV] gamma=11 ........................................................\n",
      "[CV] ......................................... gamma=11, total=   5.8s\n",
      "[CV] gamma=11 ........................................................\n",
      "[CV] ......................................... gamma=11, total=   5.5s\n",
      "[CV] gamma=11 ........................................................\n",
      "[CV] ......................................... gamma=11, total=   5.6s\n",
      "[CV] gamma=12 ........................................................\n",
      "[CV] ......................................... gamma=12, total=   5.8s\n",
      "[CV] gamma=12 ........................................................\n",
      "[CV] ......................................... gamma=12, total=   5.8s\n",
      "[CV] gamma=12 ........................................................\n",
      "[CV] ......................................... gamma=12, total=   5.7s\n",
      "[CV] gamma=12 ........................................................\n",
      "[CV] ......................................... gamma=12, total=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 29s, sys: 146 ms, total: 19min 29s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[7, 8, 9, 10, 11, 12]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=2, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.677907</td>\n",
       "      <td>0.043908</td>\n",
       "      <td>0.638370</td>\n",
       "      <td>0.695914</td>\n",
       "      <td>7</td>\n",
       "      <td>{'gamma': 7}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.805411</td>\n",
       "      <td>0.288381</td>\n",
       "      <td>0.802545</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>0.588934</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.586766</td>\n",
       "      <td>0.168260</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.361105</td>\n",
       "      <td>0.108071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.638419</td>\n",
       "      <td>0.044035</td>\n",
       "      <td>0.639563</td>\n",
       "      <td>0.686913</td>\n",
       "      <td>8</td>\n",
       "      <td>{'gamma': 8}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269389</td>\n",
       "      <td>0.797045</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.794539</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.576554</td>\n",
       "      <td>0.151436</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.359990</td>\n",
       "      <td>0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.634599</td>\n",
       "      <td>0.041318</td>\n",
       "      <td>0.638757</td>\n",
       "      <td>0.679067</td>\n",
       "      <td>9</td>\n",
       "      <td>{'gamma': 9}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.269392</td>\n",
       "      <td>0.791620</td>\n",
       "      <td>0.287008</td>\n",
       "      <td>0.790118</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.568635</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.565894</td>\n",
       "      <td>0.156081</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.360611</td>\n",
       "      <td>0.111808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.673477</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.638928</td>\n",
       "      <td>0.673533</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gamma': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.269187</td>\n",
       "      <td>0.787203</td>\n",
       "      <td>0.287734</td>\n",
       "      <td>0.784950</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.562730</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.559250</td>\n",
       "      <td>0.187961</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.360527</td>\n",
       "      <td>0.112553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.833161</td>\n",
       "      <td>0.041175</td>\n",
       "      <td>0.639180</td>\n",
       "      <td>0.669425</td>\n",
       "      <td>11</td>\n",
       "      <td>{'gamma': 11}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.270652</td>\n",
       "      <td>0.784425</td>\n",
       "      <td>0.287228</td>\n",
       "      <td>0.782239</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.557150</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.553886</td>\n",
       "      <td>0.387181</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.360288</td>\n",
       "      <td>0.113916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.702707</td>\n",
       "      <td>0.039374</td>\n",
       "      <td>0.638185</td>\n",
       "      <td>0.666278</td>\n",
       "      <td>12</td>\n",
       "      <td>{'gamma': 12}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.269950</td>\n",
       "      <td>0.782325</td>\n",
       "      <td>0.284482</td>\n",
       "      <td>0.778872</td>\n",
       "      <td>0.999191</td>\n",
       "      <td>0.553523</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.550392</td>\n",
       "      <td>0.094344</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.361006</td>\n",
       "      <td>0.114332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       5.677907         0.043908         0.638370          0.695914   \n",
       "1       5.638419         0.044035         0.639563          0.686913   \n",
       "2       5.634599         0.041318         0.638757          0.679067   \n",
       "3       5.673477         0.040909         0.638928          0.673533   \n",
       "4       5.833161         0.041175         0.639180          0.669425   \n",
       "5       5.702707         0.039374         0.638185          0.666278   \n",
       "\n",
       "  param_gamma         params  rank_test_score  split0_test_score  \\\n",
       "0           7   {'gamma': 7}                5           0.266317   \n",
       "1           8   {'gamma': 8}                1           0.269389   \n",
       "2           9   {'gamma': 9}                4           0.269392   \n",
       "3          10  {'gamma': 10}                3           0.269187   \n",
       "4          11  {'gamma': 11}                2           0.270652   \n",
       "5          12  {'gamma': 12}                6           0.269950   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.805411           0.288381            0.802545   \n",
       "1            0.797045           0.289903            0.794539   \n",
       "2            0.791620           0.287008            0.790118   \n",
       "3            0.787203           0.287734            0.784950   \n",
       "4            0.784425           0.287228            0.782239   \n",
       "5            0.782325           0.284482            0.778872   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999564            0.588934           0.999218   \n",
       "1           0.999443            0.579512           0.999515   \n",
       "2           0.999404            0.568635           0.999224   \n",
       "3           0.999527            0.562730           0.999265   \n",
       "4           0.999426            0.557150           0.999415   \n",
       "5           0.999191            0.553523           0.999116   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.586766      0.168260        0.001377        0.361105   \n",
       "1            0.576554      0.151436        0.001420        0.359990   \n",
       "2            0.565894      0.156081        0.002044        0.360611   \n",
       "3            0.559250      0.187961        0.001760        0.360527   \n",
       "4            0.553886      0.387181        0.001803        0.360288   \n",
       "5            0.550392      0.094344        0.001972        0.361006   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.108071  \n",
       "1         0.108888  \n",
       "2         0.111808  \n",
       "3         0.112553  \n",
       "4         0.113916  \n",
       "5         0.114332  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 8}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 16s, sys: 158 ms, total: 20min 16s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'max_depth':[4, 5, 6, 7, 8, 9, 10]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.938380</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>0.635418</td>\n",
       "      <td>0.653774</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.265269</td>\n",
       "      <td>0.772493</td>\n",
       "      <td>0.281303</td>\n",
       "      <td>0.769264</td>\n",
       "      <td>0.997221</td>\n",
       "      <td>0.537511</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.535829</td>\n",
       "      <td>0.136315</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.362176</td>\n",
       "      <td>0.117111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.567990</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.637221</td>\n",
       "      <td>0.661361</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.268349</td>\n",
       "      <td>0.779177</td>\n",
       "      <td>0.283506</td>\n",
       "      <td>0.776288</td>\n",
       "      <td>0.998498</td>\n",
       "      <td>0.545701</td>\n",
       "      <td>0.998530</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.361333</td>\n",
       "      <td>0.116377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.249668</td>\n",
       "      <td>0.040295</td>\n",
       "      <td>0.637915</td>\n",
       "      <td>0.668780</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.268841</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>0.285206</td>\n",
       "      <td>0.781011</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.555040</td>\n",
       "      <td>0.998967</td>\n",
       "      <td>0.555351</td>\n",
       "      <td>0.090138</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.360938</td>\n",
       "      <td>0.113589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.914240</td>\n",
       "      <td>0.039816</td>\n",
       "      <td>0.638154</td>\n",
       "      <td>0.677570</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.266969</td>\n",
       "      <td>0.790645</td>\n",
       "      <td>0.287386</td>\n",
       "      <td>0.788112</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.566695</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.564829</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.361049</td>\n",
       "      <td>0.111814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.684920</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>0.639563</td>\n",
       "      <td>0.686913</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.269389</td>\n",
       "      <td>0.797045</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.794539</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.576554</td>\n",
       "      <td>0.122176</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.359990</td>\n",
       "      <td>0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.397915</td>\n",
       "      <td>0.046613</td>\n",
       "      <td>0.639972</td>\n",
       "      <td>0.694470</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272781</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.287962</td>\n",
       "      <td>0.801543</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>0.588365</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.584614</td>\n",
       "      <td>0.185158</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>0.107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.238119</td>\n",
       "      <td>0.049943</td>\n",
       "      <td>0.640327</td>\n",
       "      <td>0.704732</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269734</td>\n",
       "      <td>0.809899</td>\n",
       "      <td>0.292336</td>\n",
       "      <td>0.809038</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>0.601585</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.598407</td>\n",
       "      <td>0.168636</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.359380</td>\n",
       "      <td>0.104743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       2.938380         0.033348         0.635418          0.653774   \n",
       "1       3.567990         0.033409         0.637221          0.661361   \n",
       "2       4.249668         0.040295         0.637915          0.668780   \n",
       "3       4.914240         0.039816         0.638154          0.677570   \n",
       "4       5.684920         0.043921         0.639563          0.686913   \n",
       "5       6.397915         0.046613         0.639972          0.694470   \n",
       "6       7.238119         0.049943         0.640327          0.704732   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               4   {'max_depth': 4}                7           0.265269   \n",
       "1               5   {'max_depth': 5}                6           0.268349   \n",
       "2               6   {'max_depth': 6}                5           0.268841   \n",
       "3               7   {'max_depth': 7}                4           0.266969   \n",
       "4               8   {'max_depth': 8}                3           0.269389   \n",
       "5               9   {'max_depth': 9}                2           0.272781   \n",
       "6              10  {'max_depth': 10}                1           0.269734   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.772493           0.281303            0.769264   \n",
       "1            0.779177           0.283506            0.776288   \n",
       "2            0.783717           0.285206            0.781011   \n",
       "3            0.790645           0.287386            0.788112   \n",
       "4            0.797045           0.289903            0.794539   \n",
       "5            0.803358           0.287962            0.801543   \n",
       "6            0.809899           0.292336            0.809038   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.997221            0.537511           0.997879   \n",
       "1           0.998498            0.545701           0.998530   \n",
       "2           0.998647            0.555040           0.998967   \n",
       "3           0.999323            0.566695           0.998940   \n",
       "4           0.999443            0.579512           0.999515   \n",
       "5           0.999574            0.588365           0.999570   \n",
       "6           0.999589            0.601585           0.999646   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.535829      0.136315        0.007345        0.362176   \n",
       "1            0.544278      0.055569        0.000861        0.361333   \n",
       "2            0.555351      0.090138        0.006373        0.360938   \n",
       "3            0.564829      0.137833        0.001559        0.361049   \n",
       "4            0.576554      0.122176        0.001906        0.359990   \n",
       "5            0.584614      0.185158        0.001225        0.359640   \n",
       "6            0.598407      0.168636        0.001391        0.359380   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.117111  \n",
       "1         0.116377  \n",
       "2         0.113589  \n",
       "3         0.111814  \n",
       "4         0.108888  \n",
       "5         0.107991  \n",
       "6         0.104743  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 21s, sys: 382 ms, total: 32min 22s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'max_depth':[10, 11, 12, 13, 14, 15]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.291422</td>\n",
       "      <td>0.050390</td>\n",
       "      <td>0.640327</td>\n",
       "      <td>0.704732</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.269734</td>\n",
       "      <td>0.809899</td>\n",
       "      <td>0.292336</td>\n",
       "      <td>0.809038</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>0.601585</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.598407</td>\n",
       "      <td>0.217196</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.359380</td>\n",
       "      <td>0.104743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.062509</td>\n",
       "      <td>0.053481</td>\n",
       "      <td>0.640653</td>\n",
       "      <td>0.713405</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 11}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275115</td>\n",
       "      <td>0.816931</td>\n",
       "      <td>0.288249</td>\n",
       "      <td>0.816505</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.610366</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.609817</td>\n",
       "      <td>0.222036</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.359001</td>\n",
       "      <td>0.103314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.973423</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.639315</td>\n",
       "      <td>0.722825</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.270535</td>\n",
       "      <td>0.825247</td>\n",
       "      <td>0.287374</td>\n",
       "      <td>0.820551</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.623669</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.621832</td>\n",
       "      <td>0.217176</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.360410</td>\n",
       "      <td>0.100090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.940121</td>\n",
       "      <td>0.068896</td>\n",
       "      <td>0.639059</td>\n",
       "      <td>0.730408</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270881</td>\n",
       "      <td>0.830283</td>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.828633</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.634856</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.627861</td>\n",
       "      <td>0.459109</td>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.360706</td>\n",
       "      <td>0.099082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.284785</td>\n",
       "      <td>0.065647</td>\n",
       "      <td>0.638407</td>\n",
       "      <td>0.739236</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.268664</td>\n",
       "      <td>0.836643</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.832775</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.646870</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.640655</td>\n",
       "      <td>0.871001</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>0.095508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.719701</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.638742</td>\n",
       "      <td>0.747799</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.269995</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.285377</td>\n",
       "      <td>0.838022</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.654907</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.653313</td>\n",
       "      <td>0.320264</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.361097</td>\n",
       "      <td>0.093723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       7.291422         0.050390         0.640327          0.704732   \n",
       "1       8.062509         0.053481         0.640653          0.713405   \n",
       "2       8.973423         0.056637         0.639315          0.722825   \n",
       "3       9.940121         0.068896         0.639059          0.730408   \n",
       "4      11.284785         0.065647         0.638407          0.739236   \n",
       "5      11.719701         0.074800         0.638742          0.747799   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0              10  {'max_depth': 10}                2           0.269734   \n",
       "1              11  {'max_depth': 11}                1           0.275115   \n",
       "2              12  {'max_depth': 12}                3           0.270535   \n",
       "3              13  {'max_depth': 13}                4           0.270881   \n",
       "4              14  {'max_depth': 14}                6           0.268664   \n",
       "5              15  {'max_depth': 15}                5           0.269995   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.809899           0.292336            0.809038   \n",
       "1            0.816931           0.288249            0.816505   \n",
       "2            0.825247           0.287374            0.820551   \n",
       "3            0.830283           0.285904            0.828633   \n",
       "4            0.836643           0.285427            0.832775   \n",
       "5            0.844954           0.285377            0.838022   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999589            0.601585           0.999646   \n",
       "1           0.999699            0.610366           0.999549   \n",
       "2           0.999666            0.623669           0.999685   \n",
       "3           0.999701            0.634856           0.999750   \n",
       "4           0.999748            0.646870           0.999790   \n",
       "5           0.999823            0.654907           0.999772   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.598407      0.217196        0.001409        0.359380   \n",
       "1            0.609817      0.222036        0.001878        0.359001   \n",
       "2            0.621832      0.217176        0.001854        0.360410   \n",
       "3            0.627861      0.459109        0.009321        0.360706   \n",
       "4            0.640655      0.871001        0.001249        0.361410   \n",
       "5            0.653313      0.320264        0.009747        0.361097   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.104743  \n",
       "1         0.103314  \n",
       "2         0.100090  \n",
       "3         0.099082  \n",
       "4         0.095508  \n",
       "5         0.093723  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 41s, sys: 247 ms, total: 27min 41s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, max_depth=11, colsample_bytree=0.5, n_estimators=200, n_jobs=8)\n",
    "parameters = {'min_child_weight':[1, 2, 3, 4, 5, 6]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.237641</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.640653</td>\n",
       "      <td>0.713405</td>\n",
       "      <td>1</td>\n",
       "      <td>{'min_child_weight': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.275115</td>\n",
       "      <td>0.816931</td>\n",
       "      <td>0.288249</td>\n",
       "      <td>0.816505</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.610366</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.609817</td>\n",
       "      <td>0.325151</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.359001</td>\n",
       "      <td>0.103314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.077434</td>\n",
       "      <td>0.053939</td>\n",
       "      <td>0.640059</td>\n",
       "      <td>0.713487</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_child_weight': 2}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.817036</td>\n",
       "      <td>0.290291</td>\n",
       "      <td>0.814887</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>0.611930</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.610096</td>\n",
       "      <td>0.238587</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.359762</td>\n",
       "      <td>0.102479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.094199</td>\n",
       "      <td>0.054341</td>\n",
       "      <td>0.640885</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>3</td>\n",
       "      <td>{'min_child_weight': 3}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.274128</td>\n",
       "      <td>0.816174</td>\n",
       "      <td>0.290082</td>\n",
       "      <td>0.814828</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.609413</td>\n",
       "      <td>0.285149</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.358824</td>\n",
       "      <td>0.102697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.997970</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>0.640991</td>\n",
       "      <td>0.712403</td>\n",
       "      <td>4</td>\n",
       "      <td>{'min_child_weight': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274127</td>\n",
       "      <td>0.817448</td>\n",
       "      <td>0.290482</td>\n",
       "      <td>0.814538</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.610051</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.607577</td>\n",
       "      <td>0.241974</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.358734</td>\n",
       "      <td>0.103598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.080999</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>0.640822</td>\n",
       "      <td>0.711850</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_child_weight': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.272256</td>\n",
       "      <td>0.817943</td>\n",
       "      <td>0.291580</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.609153</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>0.607730</td>\n",
       "      <td>0.237496</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.358969</td>\n",
       "      <td>0.103427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.069721</td>\n",
       "      <td>0.055805</td>\n",
       "      <td>0.640990</td>\n",
       "      <td>0.710621</td>\n",
       "      <td>6</td>\n",
       "      <td>{'min_child_weight': 6}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.292144</td>\n",
       "      <td>0.812906</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.608222</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.607023</td>\n",
       "      <td>0.186051</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.103001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       8.237641         0.054085         0.640653          0.713405   \n",
       "1       8.077434         0.053939         0.640059          0.713487   \n",
       "2       8.094199         0.054341         0.640885          0.712807   \n",
       "3       7.997970         0.054099         0.640991          0.712403   \n",
       "4       8.080999         0.053159         0.640822          0.711850   \n",
       "5       8.069721         0.055805         0.640990          0.710621   \n",
       "\n",
       "  param_min_child_weight                   params  rank_test_score  \\\n",
       "0                      1  {'min_child_weight': 1}                5   \n",
       "1                      2  {'min_child_weight': 2}                6   \n",
       "2                      3  {'min_child_weight': 3}                3   \n",
       "3                      4  {'min_child_weight': 4}                1   \n",
       "4                      5  {'min_child_weight': 5}                4   \n",
       "5                      6  {'min_child_weight': 6}                2   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.275115            0.816931           0.288249   \n",
       "1           0.270439            0.817036           0.290291   \n",
       "2           0.274128            0.816174           0.290082   \n",
       "3           0.274127            0.817448           0.290482   \n",
       "4           0.272256            0.817943           0.291580   \n",
       "5           0.272464            0.814333           0.292144   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.816505           0.999699            0.610366   \n",
       "1            0.814887           0.999749            0.611930   \n",
       "2            0.814828           0.999645            0.610811   \n",
       "3            0.814538           0.999720            0.610051   \n",
       "4            0.812575           0.999739            0.609153   \n",
       "5            0.812906           0.999717            0.608222   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.999549            0.609817      0.325151        0.001206   \n",
       "1           0.999755            0.610096      0.238587        0.002041   \n",
       "2           0.999684            0.609413      0.285149        0.002313   \n",
       "3           0.999636            0.607577      0.241974        0.002858   \n",
       "4           0.999713            0.607730      0.237496        0.002098   \n",
       "5           0.999633            0.607023      0.186051        0.002676   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.359001         0.103314  \n",
       "1        0.359762         0.102479  \n",
       "2        0.358824         0.102697  \n",
       "3        0.358734         0.103598  \n",
       "4        0.358969         0.103427  \n",
       "5        0.358753         0.103001  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 54s, sys: 273 ms, total: 18min 54s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, max_depth=11, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'colsample_bytree':[0.2, 0.4, 0.6, 0.8]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.387562</td>\n",
       "      <td>0.053567</td>\n",
       "      <td>0.640548</td>\n",
       "      <td>0.679050</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'colsample_bytree': 0.2}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.273027</td>\n",
       "      <td>0.791025</td>\n",
       "      <td>0.289616</td>\n",
       "      <td>0.789279</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.569715</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.566183</td>\n",
       "      <td>0.187305</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.359274</td>\n",
       "      <td>0.111110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.375610</td>\n",
       "      <td>0.058242</td>\n",
       "      <td>0.641437</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274095</td>\n",
       "      <td>0.810542</td>\n",
       "      <td>0.292237</td>\n",
       "      <td>0.808609</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.599796</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.596504</td>\n",
       "      <td>1.561276</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.358329</td>\n",
       "      <td>0.105721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.908422</td>\n",
       "      <td>0.053923</td>\n",
       "      <td>0.640217</td>\n",
       "      <td>0.718010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.6}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.272466</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>0.289308</td>\n",
       "      <td>0.818079</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.999604</td>\n",
       "      <td>0.614343</td>\n",
       "      <td>0.281345</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.359380</td>\n",
       "      <td>0.101447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.347601</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.639434</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.8}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270148</td>\n",
       "      <td>0.831490</td>\n",
       "      <td>0.288291</td>\n",
       "      <td>0.825282</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.631046</td>\n",
       "      <td>0.346508</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.360271</td>\n",
       "      <td>0.096783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       4.387562         0.053567         0.640548          0.679050   \n",
       "1       8.375610         0.058242         0.641437          0.703863   \n",
       "2       8.908422         0.053923         0.640217          0.718010   \n",
       "3      11.347601         0.053543         0.639434          0.731667   \n",
       "\n",
       "  param_colsample_bytree                     params  rank_test_score  \\\n",
       "0                    0.2  {'colsample_bytree': 0.2}                2   \n",
       "1                    0.4  {'colsample_bytree': 0.4}                1   \n",
       "2                    0.6  {'colsample_bytree': 0.6}                3   \n",
       "3                    0.8  {'colsample_bytree': 0.8}                4   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.273027            0.791025           0.289616   \n",
       "1           0.274095            0.810542           0.292237   \n",
       "2           0.272466            0.820800           0.289308   \n",
       "3           0.270148            0.831490           0.288291   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.789279           0.999755            0.569715   \n",
       "1            0.808609           0.999733            0.599796   \n",
       "2            0.818079           0.999492            0.618817   \n",
       "3            0.825282           0.999718            0.638851   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.999794            0.566183      0.187305        0.004884   \n",
       "1           0.999685            0.596504      1.561276        0.010279   \n",
       "2           0.999604            0.614343      0.281345        0.001403   \n",
       "3           0.999578            0.631046      0.346508        0.000886   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.359274         0.111110  \n",
       "1        0.358329         0.105721  \n",
       "2        0.359380         0.101447  \n",
       "3        0.360271         0.096783  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.4}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Round2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 2s, sys: 202 ms, total: 19min 2s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, max_depth=11, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'colsample_bytree':[0.3, 0.35, 0.4, 0.45, 0.5]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.350633</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.641571</td>\n",
       "      <td>0.693802</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'colsample_bytree': 0.3}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.801964</td>\n",
       "      <td>0.291045</td>\n",
       "      <td>0.798238</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>0.587712</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.587294</td>\n",
       "      <td>0.246867</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.358186</td>\n",
       "      <td>0.106307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.921857</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.641846</td>\n",
       "      <td>0.697942</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'colsample_bytree': 0.35}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274497</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>0.293480</td>\n",
       "      <td>0.802643</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.593349</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.590044</td>\n",
       "      <td>0.162569</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.357920</td>\n",
       "      <td>0.106257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.649817</td>\n",
       "      <td>0.052378</td>\n",
       "      <td>0.641437</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.4}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.274095</td>\n",
       "      <td>0.810542</td>\n",
       "      <td>0.292237</td>\n",
       "      <td>0.808609</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.599796</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.596504</td>\n",
       "      <td>0.160903</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.358329</td>\n",
       "      <td>0.105721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.175133</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>0.640587</td>\n",
       "      <td>0.708513</td>\n",
       "      <td>0.45</td>\n",
       "      <td>{'colsample_bytree': 0.45}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.271906</td>\n",
       "      <td>0.810832</td>\n",
       "      <td>0.291098</td>\n",
       "      <td>0.812100</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.606332</td>\n",
       "      <td>0.249218</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.359149</td>\n",
       "      <td>0.102955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.942383</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.640991</td>\n",
       "      <td>0.712403</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bytree': 0.5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.274127</td>\n",
       "      <td>0.817448</td>\n",
       "      <td>0.290482</td>\n",
       "      <td>0.814538</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.610051</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.607577</td>\n",
       "      <td>0.417352</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.358734</td>\n",
       "      <td>0.103598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       5.350633         0.051330         0.641571          0.693802   \n",
       "1       5.921857         0.052240         0.641846          0.697942   \n",
       "2       6.649817         0.052378         0.641437          0.703863   \n",
       "3       7.175133         0.053208         0.640587          0.708513   \n",
       "4       7.942383         0.053030         0.640991          0.712403   \n",
       "\n",
       "  param_colsample_bytree                      params  rank_test_score  \\\n",
       "0                    0.3   {'colsample_bytree': 0.3}                2   \n",
       "1                   0.35  {'colsample_bytree': 0.35}                1   \n",
       "2                    0.4   {'colsample_bytree': 0.4}                3   \n",
       "3                   0.45  {'colsample_bytree': 0.45}                5   \n",
       "4                    0.5   {'colsample_bytree': 0.5}                4   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.275806            0.801964           0.291045   \n",
       "1           0.274497            0.805732           0.293480   \n",
       "2           0.274095            0.810542           0.292237   \n",
       "3           0.271906            0.810832           0.291098   \n",
       "4           0.274127            0.817448           0.290482   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.798238           0.999743            0.587712   \n",
       "1            0.802643           0.999720            0.593349   \n",
       "2            0.808609           0.999733            0.599796   \n",
       "3            0.812100           0.999712            0.604789   \n",
       "4            0.814538           0.999720            0.610051   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.999689            0.587294      0.246867        0.001187   \n",
       "1           0.999687            0.590044      0.162569        0.001385   \n",
       "2           0.999685            0.596504      0.160903        0.001646   \n",
       "3           0.999632            0.606332      0.249218        0.000962   \n",
       "4           0.999636            0.607577      0.417352        0.002415   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.358186         0.106307  \n",
       "1        0.357920         0.106257  \n",
       "2        0.358329         0.105721  \n",
       "3        0.359149         0.102955  \n",
       "4        0.358734         0.103598  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.35}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 36s, sys: 186 ms, total: 20min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=8, max_depth=11, colsample_bytree=0.35, \n",
    "                    min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'subsample':[0.7, 0.75, 0.8, 0.85, 0.9]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.512722</td>\n",
       "      <td>0.052166</td>\n",
       "      <td>0.639575</td>\n",
       "      <td>0.696473</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'subsample': 0.7}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.804657</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>0.801801</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.592094</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>0.587340</td>\n",
       "      <td>0.124675</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.360165</td>\n",
       "      <td>0.106774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.300937</td>\n",
       "      <td>0.052205</td>\n",
       "      <td>0.639630</td>\n",
       "      <td>0.697293</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'subsample': 0.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.271918</td>\n",
       "      <td>0.804131</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.801914</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.593749</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.589379</td>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.360056</td>\n",
       "      <td>0.105743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.141876</td>\n",
       "      <td>0.051761</td>\n",
       "      <td>0.639808</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.8}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.269611</td>\n",
       "      <td>0.806104</td>\n",
       "      <td>0.290170</td>\n",
       "      <td>0.802141</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.592419</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.591663</td>\n",
       "      <td>0.076254</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.359991</td>\n",
       "      <td>0.106050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.925067</td>\n",
       "      <td>0.051797</td>\n",
       "      <td>0.641516</td>\n",
       "      <td>0.699364</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'subsample': 0.85}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.804949</td>\n",
       "      <td>0.290781</td>\n",
       "      <td>0.803458</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.595723</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.089452</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.358280</td>\n",
       "      <td>0.104844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.744444</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>0.640771</td>\n",
       "      <td>0.700170</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.9}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272261</td>\n",
       "      <td>0.806717</td>\n",
       "      <td>0.291299</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.595863</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.593487</td>\n",
       "      <td>0.122403</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.359055</td>\n",
       "      <td>0.105501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       7.512722         0.052166         0.639575          0.696473   \n",
       "1       7.300937         0.052205         0.639630          0.697293   \n",
       "2       7.141876         0.051761         0.639808          0.698082   \n",
       "3       6.925067         0.051797         0.641516          0.699364   \n",
       "4       6.744444         0.052498         0.640771          0.700170   \n",
       "\n",
       "  param_subsample               params  rank_test_score  split0_test_score  \\\n",
       "0             0.7   {'subsample': 0.7}                5           0.270968   \n",
       "1            0.75  {'subsample': 0.75}                4           0.271918   \n",
       "2             0.8   {'subsample': 0.8}                3           0.269611   \n",
       "3            0.85  {'subsample': 0.85}                1           0.275770   \n",
       "4             0.9   {'subsample': 0.9}                2           0.272261   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.804657           0.287951            0.801801   \n",
       "1            0.804131           0.287312            0.801914   \n",
       "2            0.806104           0.290170            0.802141   \n",
       "3            0.804949           0.290781            0.803458   \n",
       "4            0.806717           0.291299            0.804612   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999733            0.592094           0.999647   \n",
       "1           0.999638            0.593749           0.999652   \n",
       "2           0.999723            0.592419           0.999728   \n",
       "3           0.999722            0.595723           0.999792   \n",
       "4           0.999758            0.595863           0.999768   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.587340      0.124675        0.000997        0.360165   \n",
       "1            0.589379      0.077002        0.001942        0.360056   \n",
       "2            0.591663      0.076254        0.001152        0.359991   \n",
       "3            0.593327      0.089452        0.000899        0.358280   \n",
       "4            0.593487      0.122403        0.001336        0.359055   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.106774  \n",
       "1         0.105743  \n",
       "2         0.106050  \n",
       "3         0.104844  \n",
       "4         0.105501  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.85}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 50s, sys: 260 ms, total: 45min 50s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(subsample=0.85, max_depth=11, min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'gamma':[6, 7, 8, 9, 10]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.057908</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.632603</td>\n",
       "      <td>0.800896</td>\n",
       "      <td>6</td>\n",
       "      <td>{'gamma': 6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.258941</td>\n",
       "      <td>0.877595</td>\n",
       "      <td>0.272010</td>\n",
       "      <td>0.875930</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.722028</td>\n",
       "      <td>0.349732</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.367156</td>\n",
       "      <td>0.075898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.026607</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.634629</td>\n",
       "      <td>0.771504</td>\n",
       "      <td>7</td>\n",
       "      <td>{'gamma': 7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.262813</td>\n",
       "      <td>0.857569</td>\n",
       "      <td>0.276339</td>\n",
       "      <td>0.855067</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.689843</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.683538</td>\n",
       "      <td>0.311169</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.365084</td>\n",
       "      <td>0.084848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.058890</td>\n",
       "      <td>0.055907</td>\n",
       "      <td>0.638910</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>8</td>\n",
       "      <td>{'gamma': 8}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.271630</td>\n",
       "      <td>0.838614</td>\n",
       "      <td>0.284611</td>\n",
       "      <td>0.838432</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.657327</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.648151</td>\n",
       "      <td>0.315873</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.360818</td>\n",
       "      <td>0.092949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.031816</td>\n",
       "      <td>0.051826</td>\n",
       "      <td>0.639711</td>\n",
       "      <td>0.724002</td>\n",
       "      <td>9</td>\n",
       "      <td>{'gamma': 9}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275518</td>\n",
       "      <td>0.824704</td>\n",
       "      <td>0.284121</td>\n",
       "      <td>0.822919</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.626510</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.621877</td>\n",
       "      <td>0.250194</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.359904</td>\n",
       "      <td>0.099825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.990860</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.639295</td>\n",
       "      <td>0.708510</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gamma': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.271369</td>\n",
       "      <td>0.813366</td>\n",
       "      <td>0.286612</td>\n",
       "      <td>0.810966</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.606851</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.602857</td>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.360345</td>\n",
       "      <td>0.103669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      16.057908         0.063478         0.632603          0.800896   \n",
       "1      16.026607         0.058327         0.634629          0.771504   \n",
       "2      16.058890         0.055907         0.638910          0.745631   \n",
       "3      16.031816         0.051826         0.639711          0.724002   \n",
       "4      15.990860         0.049427         0.639295          0.708510   \n",
       "\n",
       "  param_gamma         params  rank_test_score  split0_test_score  \\\n",
       "0           6   {'gamma': 6}                5           0.258941   \n",
       "1           7   {'gamma': 7}                4           0.262813   \n",
       "2           8   {'gamma': 8}                3           0.271630   \n",
       "3           9   {'gamma': 9}                1           0.275518   \n",
       "4          10  {'gamma': 10}                2           0.271369   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.877595           0.272010            0.875930   \n",
       "1            0.857569           0.276339            0.855067   \n",
       "2            0.838614           0.284611            0.838432   \n",
       "3            0.824704           0.284121            0.822919   \n",
       "4            0.813366           0.286612            0.810966   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.999720            0.728033           0.999740   \n",
       "1           0.999704            0.689843           0.999659   \n",
       "2           0.999730            0.657327           0.999668   \n",
       "3           0.999595            0.626510           0.999609   \n",
       "4           0.999609            0.606851           0.999591   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.722028      0.349732        0.005596        0.367156   \n",
       "1            0.683538      0.311169        0.002126        0.365084   \n",
       "2            0.648151      0.315873        0.002573        0.360818   \n",
       "3            0.621877      0.250194        0.001928        0.359904   \n",
       "4            0.602857      0.302984        0.000978        0.360345   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.075898  \n",
       "1         0.084848  \n",
       "2         0.092949  \n",
       "3         0.099825  \n",
       "4         0.103669  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 9}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 4s, sys: 171 ms, total: 29min 4s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(gamma=9, subsample=0.85, max_depth=11, \n",
    "                    min_child_weight=4, n_estimators=200, n_jobs=8)\n",
    "parameters = {'learning_rate':[0.1, 0.05, 0.01]}\n",
    "clf = GridSearchCV(xgb, parameters, scoring=gini_scorer, cv=4, verbose=1, n_jobs=1)\n",
    "clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.968189</td>\n",
       "      <td>0.052040</td>\n",
       "      <td>0.639711</td>\n",
       "      <td>0.724002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275518</td>\n",
       "      <td>0.824704</td>\n",
       "      <td>0.284121</td>\n",
       "      <td>0.822919</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.626510</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.621877</td>\n",
       "      <td>0.326770</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.359904</td>\n",
       "      <td>0.099825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.137329</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>0.641890</td>\n",
       "      <td>0.710198</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274619</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.294560</td>\n",
       "      <td>0.810421</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.610280</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>0.607234</td>\n",
       "      <td>0.248011</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.357369</td>\n",
       "      <td>0.101450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.647211</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.624083</td>\n",
       "      <td>0.674957</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.257934</td>\n",
       "      <td>0.784184</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.780171</td>\n",
       "      <td>0.986306</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>0.984910</td>\n",
       "      <td>0.567087</td>\n",
       "      <td>0.128627</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.361540</td>\n",
       "      <td>0.107231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      15.968189         0.052040         0.639711          0.724002   \n",
       "1      16.137329         0.062801         0.641890          0.710198   \n",
       "2      16.647211         0.073159         0.624083          0.674957   \n",
       "\n",
       "  param_learning_rate                   params  rank_test_score  \\\n",
       "0                 0.1   {'learning_rate': 0.1}                2   \n",
       "1                0.05  {'learning_rate': 0.05}                1   \n",
       "2                0.01  {'learning_rate': 0.01}                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.275518            0.824704           0.284121   \n",
       "1           0.274619            0.812857           0.294560   \n",
       "2           0.257934            0.784184           0.267183   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.822919           0.999595            0.626510   \n",
       "1            0.810421           0.999225            0.610280   \n",
       "2            0.780171           0.986306            0.568386   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.999609            0.621877      0.326770        0.001215   \n",
       "1           0.999153            0.607234      0.248011        0.001110   \n",
       "2           0.984910            0.567087      0.128627        0.000952   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.359904         0.099825  \n",
       "1        0.357369         0.101450  \n",
       "2        0.361540         0.107231  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the best classifier so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=9, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=11, min_child_weight=4, missing=None, n_estimators=200,\n",
       "       n_jobs=8, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini=0.277+/-0.015, Best=0.307\n",
      "CPU times: user 1h 2min 31s, sys: 5.41 s, total: 1h 2min 37s\n",
      "Wall time: 8min 13s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEYCAYAAABRMYxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59646ee320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax21 = fig.add_subplot(1, 2, 1)\n",
    "ax22 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "neutral_line = np.linspace(0, 1, 10)\n",
    "ax21.plot(neutral_line, neutral_line, lw=1, ls='--')\n",
    "ax22.plot(neutral_line, 1- neutral_line, lw=1, ls='--')\n",
    "\n",
    "ginis_xgb = []\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    rstate = None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rstate)\n",
    "\n",
    "    num_class1 = np.sum(y_train)\n",
    "    num_class1_to_resample = 2 * num_class1\n",
    "    num_class0_to_resample = int(1 * num_class1_to_resample)\n",
    "\n",
    "    # First, randomly undersample the majority\n",
    "    rus = RandomUnderSampler(ratio={0: num_class0_to_resample , 1: num_class1})\n",
    "    X_tlrus, y_tlrus = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "    # Then use SMOTE to oversample the minority\n",
    "    smote = SMOTE(ratio={0: num_class0_to_resample , 1: num_class1_to_resample}, n_jobs=8)\n",
    "    X_res, y_res = smote.fit_sample(X_tlrus, y_tlrus)\n",
    "\n",
    "    # GradientBoost\n",
    "    clf = best_xgb\n",
    "    clf.fit(X_res, y_res)\n",
    "\n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    y_proba2 = clf.predict_proba(X_test)\n",
    "    ginis_xgb.append(my_gini(y_test, y_proba2))\n",
    "    report2 = classification_report(y_test, y_pred2, digits=4,\n",
    "                                   labels=None, target_names=None)\n",
    "\n",
    "    precision2, recall2, _ = precision_recall_curve(y_test, y_proba2[:, 1], pos_label=1)\n",
    "    fpr2, tpr2, _ = roc_curve(y_test, y_proba2[:, 1], pos_label=1)\n",
    "    ax21.plot(fpr2, tpr2)\n",
    "    ax21.set_xlabel('False Positive Rate')\n",
    "    ax21.set_ylabel('True Positive Rate')\n",
    "    ax21.set_title('GradientBoost ROC')\n",
    "    ax22.plot(recall2, precision2)\n",
    "    ax22.set_xlabel('Recall')\n",
    "    ax22.set_ylabel('Precision')\n",
    "    ax22.set_title('GradientBoost Precision-Recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Gini=%.3f+/-%.3f, Best=%.3f' % (np.mean(ginis_xgb), np.std(ginis_xgb), np.max(ginis_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
